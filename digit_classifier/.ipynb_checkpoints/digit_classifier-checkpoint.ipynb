{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to do a few things here:\n",
    "\n",
    "- We want to train a model to identify digits for the individual sudoku cell image that the Recognizer has prepared.\n",
    "- We want to use this as a Tensorflow Model in the C++\n",
    "\n",
    "So what are the steps?\n",
    "\n",
    "1. First train the sudoku digit classifier (aka SudokuNet) model using the MNIST dataset, w/ keras \n",
    "2. Save the model to the `/output` folder\n",
    "3. Convert this `model.h5` keras file to a tensorflow `.pb` file\n",
    "4. Visualize the graph in this notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What was used\n",
    "- `python 3.6`\n",
    "- `conda`\n",
    "- `pip`\n",
    "```\n",
    "keras                     2.3.1                    py36_0    conda-forge\n",
    "opencv                    4.1.0            py36h3aa1047_6    conda-forge\n",
    "scikit-learn              0.23.1           py36h0e1014b_0    conda-forge\n",
    "tensorflow                2.3.0                    pypi_0    pypi\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Train SudokuNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.sudoku_net import SudokuNet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial learning rate\n",
    "INIT_LEARNING_RATE = 1e-3\n",
    "# num of epochs to train\n",
    "EPOCHS = 10\n",
    "# batch size\n",
    "BATCH_SIZE = 128\n",
    "# width and height pixel size of each individual cell\n",
    "PIXEL_SIZE = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "((trainData, trainLabels), (testData, testLabels)) = mnist.load_data()\n",
    "\n",
    "# add a channel dim to the digits to indicate that they are grayscale\n",
    "trainData = trainData.reshape((trainData.shape[0], PIXEL_SIZE, PIXEL_SIZE, 1))\n",
    "testData = testData.reshape((testData.shape[0], PIXEL_SIZE, PIXEL_SIZE, 1))\n",
    "\n",
    "# add scale data to range of [0,1]\n",
    "trainData = trainData.astype(\"float32\") / 255.0\n",
    "testData = testData.astype(\"float32\") / 255.0\n",
    "\n",
    "# convert labels from int to vectors\n",
    "le = LabelBinarizer()\n",
    "trainLabels = le.fit_transform(trainLabels)\n",
    "testLabels = le.transform(testLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=INIT_LEARNING_RATE)\n",
    "model = SudokuNet.build(w=28, h=28, d=1, c=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.7102 - accuracy: 0.7668 - val_loss: 0.0941 - val_accuracy: 0.9742\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.2505 - accuracy: 0.9252 - val_loss: 0.0575 - val_accuracy: 0.9849\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1969 - accuracy: 0.9434 - val_loss: 0.0497 - val_accuracy: 0.9852\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.1615 - accuracy: 0.9530 - val_loss: 0.0396 - val_accuracy: 0.9884\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1386 - accuracy: 0.9592 - val_loss: 0.0441 - val_accuracy: 0.9866\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.1302 - accuracy: 0.9618 - val_loss: 0.0356 - val_accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1167 - accuracy: 0.9658 - val_loss: 0.0326 - val_accuracy: 0.9911\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.1077 - accuracy: 0.9676 - val_loss: 0.0341 - val_accuracy: 0.9909\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.1012 - accuracy: 0.9689 - val_loss: 0.0324 - val_accuracy: 0.9909\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 18s 37ms/step - loss: 0.0980 - accuracy: 0.9696 - val_loss: 0.0310 - val_accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "H = model.fit(\n",
    "    trainData, trainLabels,\n",
    "    validation_data=(testData, testLabels),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       980\n",
      "           1       1.00      0.99      1.00      1135\n",
      "           2       0.99      1.00      0.99      1032\n",
      "           3       1.00      0.99      1.00      1010\n",
      "           4       0.99      1.00      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       1.00      0.99      0.99       958\n",
      "           7       0.99      0.99      0.99      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       0.99      0.98      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get prediction\n",
    "pred = model.predict(testData)\n",
    "# see how the network does\n",
    "print(\n",
    "    classification_report(\n",
    "        testLabels.argmax(axis=1),\n",
    "        pred.argmax(axis=1),\n",
    "        target_names=[str(x) for x in le.classes_])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok cool, it looks like we're getting ~99%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"output/model.h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: convert keras model (`.h5`) to Tensorflow model (`.pb`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-fa9cdb0af34e>:3: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n",
      "Instructions for updating:\n",
      "Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "# this must be exec'd before loading keras model\n",
    "K.set_learning_phase(0)\n",
    "# this has to be tensorflow.keras\n",
    "# or else you'll get this -> https://stackoverflow.com/questions/58878421/unexpected-keyword-argument-ragged-in-keras\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: [<tf.Tensor 'activation_4/Softmax_2:0' shape=(None, 10) dtype=float32>], inputs:[<tf.Tensor 'conv2d_input_2:0' shape=(None, 28, 28, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "model = load_model('output/model.h5')\n",
    "# quick check, did it work?\n",
    "print(f\"outputs: {model.outputs}, \\n inputs:{model.inputs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
