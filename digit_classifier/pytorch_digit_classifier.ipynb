{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Classifier w/ PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to do a few things here:\n",
    "\n",
    "- We want to train a model to identify digits for the individual sudoku cell image that the Recognizer has prepared.\n",
    "- We want to use this as a Tensorflow Model in the C++\n",
    "\n",
    "So what are the steps?\n",
    "\n",
    "1. First train the sudoku digit classifier (aka SudokuNet) model using the MNIST dataset\n",
    "2. Save the model to the /models folder as a .pb file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep training dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    './dataset', train=True, \n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            (0.1307,), (0.3081,))\n",
    "    ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=batch_size_train, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# prep test dataset\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    './dataset', \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            (0.1307,), (0.3081,))\n",
    "    ]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size_test, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 28, 28])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAELCAYAAAD+9XA2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeQElEQVR4nO3deZSU1ZnH8d8jIogQASGgiCzihkfUuIELGkUFI+AobuNBSdRo3COGMRrj7uAWxi3EwRxQj6OjIiLGiIcI7qKBIygGFREElX0TRJZw548q37z3TlfRVX2rq7r7+zmH4/N433rf29Ttenjv+9Z9zTknAABqaptydwAAUD9QUAAAUVBQAABRUFAAAFFQUAAAUVBQAABR1OuCYmadzcyZ2bZlOPY8M+tT28dFHIwdFKshj50aFxQzO8vMpprZOjNbko0vMTOL0cFSMbO1qT9bzGx9Kj+nwH2NMbPbIvbtuqB/67N9bBPrGJWAsRN/7GT32dbM/sfMVpvZSjN7Iub+KwFjpzI/d2pUUMxsqKT7JN0tqb2kdpIulnSEpO1yvKZRTY4Zi3Ou+Q9/JH0pqX/q/yW/gOX4V4Zz7o6gf3dKmuKcW1bbfSkVxk5JPSdpkaTdJP1Y0j1l6kdJMHZK1reaf+4454r6I2lHSesknbaV7cZIGinppez2fSTtI2mKpFWSZkkakNp+iqQLUvkQSW+mcqfM4Pks+/qHJFm2rZEyvzzLJM2VdGl2+2230sd5kvpk42MkLZT0H8r8Uj4e9iHVj26Sfilpk6SNktZKmpDa5zWSZkpaLel/JTUt4u/Zsj/LecW+V5X2h7FTurEj6YTs6xuV+31m7NStsRMcp6jPnZqcofSS1ETS+Gps+++SbpfUQtJUSRMkvaLMv54ul/SEme1VwLFPlnSIpB6SzpB0Yvb/X5htO1DSwZIGFbDPtPaSWkvqpMwbl5Nz7r8lPSHpLpep7P1TzWdI6iupS7avQ35oMLNVZnZkNfpylDJ/T2ML+QEqHGNHJRs7PSV9IulRM1tuZu+b2dFF/iyViLGjyv3cqUlBaSNpmXNu8w//w8zeznZ4vZn1Tm073jn3lnNui6QDJDWXNNw5t9E596qkFyWdXcCxhzvnVjnnvpQ0ObtPKfMX+V/OuQXOuRWS/rPIn22LpBudcxucc+uL3Ick3e+c+zrblwmpfso519I592Y19nGepGedc2tr0I9Kw9jZumLHzq7KnKVMVuYD6l5J4+vR9TfGztaV7XOnJgVluaQ26bk+59zhzrmW2bb0vhek4l0kLci+yT+YL6lDAcdelIq/U2agJPsO9luMpc6574t8bVquflaLmTWTdLqkRyP0pZIwdrau2LGzXtI859yfnXObnHNPKfNzHRGhT5WAsbN1ZfvcqUlBeUfSBkkDq7FteknjryV1NLP0sXeT9FU2XiepWaqtfQF9+kZSx2C/xQiXYPb6ZGZhn0q1ZPO/SVqhzPxufcLYyb19Tc2sYp/1aUlxxk7u7WMp+nOn6ILinFsl6WZJfzSzQWbWwsy2MbMDJO2Q56VTlamaw8yssZkdI6m/pKey7R9IOtXMmplZN0nnF9CtpyVdYWa7mlkrSdcW8Np8Zkja18wOMLOmkm4K2hdL6hrpWGnnSXrMZa+S1ReMHU/ssTNOUiszO8/MGpnZIGWmwd6KeIyyYex4Ku5zp0a3DTvn7pJ0taRhyvxwiyU9rMydCm/neM1GZd7IfsrcFfFHSec652ZnNxmhzJ0Li5U55SrkHvpRkiYq80ZMV+b2yRpzzn0q6RZJk5S5yyOcg/yzpO7Zedznq7PP7H3eR+Vp7yDpWEmPFdXpCsfYSUQdO9l58wHK3OmzWpkPt4GuHt1yzthJVNznjtWzf/wCAMqkXi+9AgCoPRQUAEAUFBQAQBQUFABAFBQUAEAUBa1oaWbcElaBnHOVvmQ346YyLXPOtS13J/Jh7FSsKscOZyhAw1XsEiFAlWOHggIAiIKCAgCIgoICAIiCggIAiIKCAgCIgoICAIiCggIAiIKCAgCIgoICAIiCggIAiIKCAgCIgoICAIiioNWGgfrowgsv9PJZs2Yl8dy5c722RYsW1UqfgLqIMxQAQBQUFABAFEx5oV66+OKLvbxXr15J3KJFC6+tf//+Xr558+YqY0nq06ePl0+dOrVG/QTqE85QAABRUFAAAFFQUAAAUXANBfVS165dvfz4449P4nbt2uV97QcffJDECxYs8NouuOACL+caSt33yiuvePlhhx3m5d26dUvipUuX1kqf6irOUAAAUVBQAABRlGzKa+TIkV6enhoYM2ZMqQ6LBmrffff18nPPPdfLd9pppyR++umnvbbbb7/dy+fPn5/E33//vdfWtGnTGvUTladz585eHt5WPmnSpCTef//9a6NLdRZnKACAKCgoAIAoKCgAgCjMOVf9jc2qvXG43yVLliRx+hZOSZo5c2a1+1Dp0nP5gwcP9truvPNOL1+5cmWUYzrnLMqOSqSQcVOI9PIqt912m9fWqlUrL09fNwnfl3B5lQZkmnPu4HJ3Ip9SjZ20e+65x8uvvvrqnNt+/vnnXv6nP/3Jy8ePHx+lT19++aWXb9y4Mcp+I6py7HCGAgCIgoICAIiCggIAiKJk30NZvXq1l7dp0yaJzzzzTK9tzpw5Sfzdd9+VqkvRtG7dOonPPvtsr+3GG29M4vR3HySpffv2Xj5kyJD4nWtA0kvSh9dMQunvmjTgayaowvLly/O2b9iwIYk7duzotd19991582INHTrUy0eMGBFlv6XGGQoAIAoKCgAgipLdNvyzn/3My1944YWc244dOzaJhw8f7rUtWrTIy7/++uvqdqEgu+22WxIfeuihXlu/fv28/Oijj07iLl26VPsYc+fO9fI99tijkC7m1FBvG04vi9K4cWOvLVxeJb0Uy6ZNm0rRnbqI24YlnXDCCV7+8ssve/n555+fxNOnT/faBgwY4OWzZ89O4m+//Tbvcc3+9Wv71FNPeW3h595ee+2Vd19lwG3DAIDSoaAAAKKgoAAAoijZbcMTJ0708vS85Iknnui1nXbaaUkcXnsJ57vTSxCE11OaNGni5c8880zO/oW3mabn2Js3b57zdTXx/PPPl2S/DUX6yXmSPwcdCpekr4TrJm3btk3iRx55xGv7+OOPk3j9+vVe22OPPebl8+bNi9+5Buzwww/38hUrVnj56NGjc752xowZUfoQ3sr+5JNPRtlvbeMMBQAQBQUFABAFBQUAEEXJrqGEc4LpayO33nqr13bRRRclcbhcSb5Hrobbhq6//vqt9rMq48aN8/KjjjrKy9PLyIT++c9/JvFvf/tbr23UqFFF9QcZ4d/nttvmHr7ffPNNqbtTsCuuuCKJe/bs6bWdfPLJOV931llneXnfvn2TOFzmHDVXyHfzSnXMcvQhBs5QAABRUFAAAFGUbMornxtuuMHL//KXvyRxeHqfvp1X8lf+XLZsmdfWvXt3L09PP4XCWwH/9re/JfHPf/5zry3fbcTh1N5Pf/rTJH777bdzvg6FSy+PI0lfffVVEocrOVeCvffe28vTt6eG06bp2+HDJwhed911Xp5erTvW6rYN2ZQpU7w8XHqpVNJLOO244461csxS4wwFABAFBQUAEAUFBQAQRVmuoYTefffdKmNJuuqqq3K+LlwyIZxjD5dQSJs0aZKX//rXv07icDnrfH7/+997OddNSqdPnz5e/vnnn5epJ1Xbc889vTycm08vvRL6wx/+kMT33nuv13bBBRd4efq64hNPPOG1lerxDvVZ+D6Feak0a9YsiRs1alQrxyw1zlAAAFFQUAAAUVBQAABRVMQ1lGKF1ysKuX4RLn0ePsozn+XLlyfxyJEjq/061Ez6OoMkXXnllUkcvp/t2rXz8vR7FtMOO+yQxB06dPDa8l0zmTlzppc//PDDSbxq1SqvLXw8bHoJl/A7U+Gy/ahc6e+s1RecoQAAoqCgAACiqNNTXjWxzz77ePmRRx6Zc9twCuLUU09N4jVr1kTtF3IbOnSolx9//PFJHL6f4UrT11xzTRLHXIl4++23T+KtTZumn7x44403em3pVYPT02iS1KtXr5z7zLfyNUqvZcuWXp5+P+bMmZP3tTvvvHMSh1O24e3gdQVnKACAKCgoAIAoKCgAgCga7DWUfE9zXLt2rZeH891vvvlmSfqEwvTo0SOJ58+f77WFj0E45JBDkviMM87w2sLlSpYsWVLtPqQfoRDOe6dv75X863T5lgVat26dl7/zzjtenv5ZBg8e7LWllxBC6T3yyCNe3q9fvyR+7rnnvLYwT19vCZ/QeMopp3h5+rraQQcd5LUdccQRSRw+0iNcuuqvf/2rSokzFABAFBQUAEAUFBQAQBQN5hpKq1atvPz000/Pue3w4cO9/MEHHyxJnxDPSSed5OUvv/yyl+++++5JPG3aNK9t3rx5Xj558uSi+rC174R07do1iSdMmOC15VuKP3y0ddqIESOq2TuUwu9+9zsvb9y4cRKfc845XluY53PXXXflbPv222+9PH1tZqeddvLaunXrVu1jxsAZCgAgCgoKACCKBjPlNWzYMC/P94S0LVu2lLo7iGzWrFle3rdvXy9P38L7i1/8wmvr3Lmzl4cr+JZC79698+Zp7733npcvXrw4icOpPdSu2bNne/mZZ56ZxOFnzqBBg7w8/YTP8Dby8Emw6dWpw5WzK+nJpZyhAACioKAAAKKgoAAAorDwK/95Nzar/sYV4Cc/+UkST5061WvbZpvctfSyyy7z8kp/KqNzzra+VflU2rgJr5H07NnTy9Pz4IVIL08vSYceeqiX77333kn87LPPem3ppzuGS62kXydJQ4YMKap/VZjmnDs41s5KodLGTkyPP/54Eoe39+Z7ZEGFqHLscIYCAIiCggIAiKJe3zacvp1u7ty5Xlu+b5DOmDGjZH1C+Y0ePTpvftFFF9Vmd4D/98TGuoozFABAFBQUAEAUFBQAQBT1+hrKd999V2VclQ0bNiTxRx99VLI+AUCokK9vVDLOUAAAUVBQAABRUFAAAFHU62so+++/fxL36NEj77bjxo1L4jVr1pSsTwAQSn9WSVL//v29PHzCZ6XiDAUAEAUFBQAQRb2e8irEk08+We4uAGigmjZt6uXpldIlprwAAA0MBQUAEAUFBQAQRb2+hvLFF18kcfjExv3228/LFy5cWCt9AoD6ijMUAEAUFBQAQBQUFABAFFbIsslmVmfXWG7durWXt23b1ss/+eST2uxOVM65in5+aF0eN/XcNOfcweXuRD6MnYpV5djhDAUAEAUFBQAQRb2+bThtxYoVeXMAQM1whgIAiIKCAgCIgoICAIii0GsoyyTNL0VHULRO5e5ANTBuKhNjB8WqcuwU9D0UAAByYcoLABAFBQUAEAUFBQAQBQUFABAFBQUAEAUFBQAQBQUFABAFBQUAEAUFBQAQBQUFABAFBQUAEAUFBQAQBQUFABBFvS4oZtbZzJyZ1fqjjs1snpn1qe3jIg7GDorVkMdOjQuKmZ1lZlPNbJ2ZLcnGl5iZxehgqZjZ2tSfLWa2PpWfU+C+xpjZbRH7dky2T+k+nhdr/5WCsRN/7GT32dbM/sfMVpvZSjN7Iub+KwFjpySfO9cF/Vuf7WOb6u6jRgXFzIZKuk/S3ZLaS2on6WJJR0jaLsdrGtXkmLE455r/8EfSl5L6p/5f8gtYjn9lZH2d7qNz7tEy9aMkGDsl9ZykRZJ2k/RjSfeUqR8lwdgpWd/uCPp3p6QpzrllheykqD+SdpS0TtJpW9lujKSRkl7Kbt9H0j6SpkhaJWmWpAGp7adIuiCVD5H0Zip3ygyez7Kvf0j/elBYI2V+eZZJmivp0uz2226lj/Mk9cnGx0haKOk/lPmlfDzsQ6of3ST9UtImSRslrZU0IbXPayTNlLRa0v9KalrNv9tjJC0s9r2p9D+MnZKOnROyr29U7veZsVO3xk5wHMv+LOcV8rqanKH0ktRE0vhqbPvvkm6X1ELSVEkTJL2izL+eLpf0hJntVcCxT5Z0iKQeks6QdGL2/1+YbTtQ0sGSBhWwz7T2klor85jLX+bb0Dn335KekHSXy1T2/qnmMyT1ldQl29chPzSY2SozOzLPrn9sZovN7AszG2FmOxT3o1Qkxo5KNnZ6SvpE0qNmttzM3jezo4v8WSoRY0cl/dz5wVHK/D2NLeQHqElBaSNpmXNu8w//w8zeznZ4vZn1Tm073jn3lnNui6QDJDWXNNw5t9E596qkFyWdXcCxhzvnVjnnvpQ0ObtPKfMX+V/OuQXOuRWS/rPIn22LpBudcxucc+uL3Ick3e+c+zrblwmpfso519I592aO183ObruzpGMlHSTpDzXoR6Vh7GxdsWNnV2XOUiYr8wF1r6TxhcyDVzjGztYVO3bSzpP0rHNubSEHrklBWS6pTXquzzl3uHOuZbYtve8FqXgXSQuyb/IP5kvqUMCxF6Xi75QZKMm+g/0WY6lz7vsiX5uWq595OecWOec+ds5tcc59IWmYpNMi9KdSMHa2rqixI2m9pHnOuT875zY5555S5uc6IkKfKgFjZ+uKHTuSJDNrJul0SQVft61JQXlH0gZJA6uxrUvFX0vqaGbpY+8m6atsvE5Ss1Rb+wL69I2kjsF+i+GC3OuTmYV9CrePzal+3eLN2Mm9fU3NrGKfpR6ftYmxk3v7WP5N0gplrisVpOgPKefcKkk3S/qjmQ0ysxZmto2ZHSAp33z/VGWq5jAza2xmx0jqL+mpbPsHkk41s2Zm1k3S+QV062lJV5jZrmbWStK1Bbw2nxmS9jWzA8ysqaSbgvbFkrpGOpbM7Kdm1skyOkoarurNGdcJjB1P1LEjaZykVmZ2npk1MrNBykyDvRXxGGXD2PHEHjs/OE/SYy57db4QNfpXr3PuLklXKzMlszj752Fl7lR4O8drNirzRvZT5q6IP0o61zk3O7vJCGXuXFiszClXIffQj5I0UZk3Yroyt0/WmHPuU0m3SJqkzF0e4RzknyV1z87jPl+dfWbv8z4qR/OByvz9rcv+90NJVxTR9YrF2ElEHTvZefMBytzps1qZD7eBrpBbPyscYycR+3NHZtZBmeu2jxXTZyuiCAEA8P/Up3l5AEAZUVAAAFFQUAAAUVBQAABRUFAAAFEUtKKlmXFLWAVyzlX6kt2Mm8q0zDnXttydyIexU7GqHDucoQANV7FLhABVjh0KCgAgCgoKACAKCgoAIAoKCgAgCgoKACAKCgoAIAoKCgAgCgoKACCKgr4pD8D3q1/9KokffPBBr+2BBx7w8quuuqo2ugSUDWcoAIAoKCgAgCgoKACAKAp6pjwrf1YmVhuuPd26dfPyyZMnJ/HOO+/stW3atMnL+/btm8SvvfZaCXpXsGnOuYPL3Yl86tPYqWeqHDucoQAAoqCgAACi4LbhIuy6665JfNxxx3ltBxxwQM7XDRo0yMs7dOiQxOvWrfPaDjvsMC//+OOPC+0mSmDgwIFevssuuyRxOH3cuHFjL2/btqKfZQXUGGcoAIAoKCgAgCgoKACAKOrVNZROnTp5+UknnZTE6bluSerRo4eXH3jggUls5t+FG86N77DDDkncqlWr4jobSO9Tktq1a+flXEMpj5YtW3r5JZdcUp6OAHUAZygAgCgoKACAKOr0lNfQoUO9fPDgwV4eTmuVwoYNG7z8008/TeKuXbt6ba+++qqXN23aNIlnzpzptU2fPj1WF1EDw4cP9/JwWjWf119/3ctfeeWVKH1CXM2aNfPy9PR3KP07K0kHH+x/WXyPPfZI4j333DPvcdOfFaHVq1d7+c0335zEa9asybvfcuIMBQAQBQUFABAFBQUAEEWdW204fTttOAfZokWLau9nwYIFXt6xY8cknjFjhtf2wgsvePlHH32UxO+8847XtnDhwmr3IRZWG44rPY6mTZvmte2+++5enr7FPPxdat++vZcvXbo0VhdjaTCrDffu3dvLr7/++iQO39MuXbqEfUjiQj4vQ5s3b/byVatWJfF2223ntf3oRz/y8kmTJiXxiSeeWHQfImK1YQBA6VBQAABRUFAAAFHUue+hHHLIIUm8tWsmo0aNSuLRo0d7benrIJI/hxkuJR9+1wT1W3p+PfwuUb459ClTpnh5eo4ctS99vfXJJ5/02sLrW/mMHz8+iceOHeu1FfKdkBUrVnj5m2++mcThYy/eeustL+/Tp0+1j1NOnKEAAKKgoAAAoqhzU15NmjTJ2bZlyxYvT5+evvvuuyXrE+qXIUOGVHvb9K3Al156qde2adOmWF1CERYvXpzEZ599tteWnqoKv0IQWr58edyOVSFcJipc4uX9998veR9i4AwFABAFBQUAEAUFBQAQRcVfQwmvmdx///05t125cqWXs1w4qqNnz55eHi57kU96mZ7Zs2dH6xPiCh8lUAnS10muvPLKvNuGj1GoVJyhAACioKAAAKKgoAAAoqj4ayjhEgk777xzzm0vv/zyUncH9UDr1q29fMSIEV4eLiWeT3o5jXvvvddrO+GEE7x84sSJSXzHHXfk3A8ahr59+yZx+Njhb775xsvDx2RUKs5QAABRUFAAAFFU/JRXv379craF0wRz5szx8u233z6J169fH7djqLO6d+/u5YceemjR+zrrrLOSOFz6J99xw6nbc845p+g+oG669tprkzhcxfqNN97w8vQyMpWMMxQAQBQUFABAFBQUAEAUFX8NJZ/w9s/33nvPy2fOnJnEN9xwg9c2YcKE0nUMFS39REYp/1MYtyZ93aSQ/Zx55ple/swzzyTx888/X3R/UHfkW+Jn3LhxtdiTeDhDAQBEQUEBAERBQQEARFHx11DC+7HT10XCx2aG0u3jx4/32j788EMvTz8S9K233vLabrrpJi///vvv8x4XlS1cEqUm11BiybekEOqHzp07e3nbtm1zbjtp0qQS96Y0OEMBAERBQQEARFHxU16zZs3y8l69eiVxuLpruGLnvvvum8TNmzf32vbbb7+cxzziiCO8fLfddvPy888/P4lZ0qVu6NChQ7m7gAYuHIPh1x6qq127dl7esWPHJP773//utZ188sle/uKLLxZ1zOriDAUAEAUFBQAQBQUFABBFxV9DCaWvWVxyySV5t917772TuGXLll7bKaec4uXppTA6derktaWXKJekbbbZJmcbKtOAAQNKst/PP/88iV9//XWvbciQISU5JirX4MGDk3ifffbx2po0aeLlZpZzP0uXLs3ZFr4ufdv7P/7xD68tvaSPxDUUAEAdQUEBAERBQQEARGGFLDthZuVfo6JE0ssi3HrrrV5b+HjWdevWJXGLFi1K2q/qcM7lnoytAJUwbi699NIkfuCBB7y2miy9kr6etrVHAKetXLnSy9u0aVN0H2pgmnPu4HIcuLoqYezk89BDD3n5hRdemMSNGjXy2vJd+9i4caPXtmDBAi8fO3ZsEi9ZssRre+mll5L4q6++8trWrl2bs+81VOXY4QwFABAFBQUAEEWdu224VObNm5fE4WljKFzeAJVvzpw5SRxOcZXjiY3cbl4/PProo14+d+7cJP7ss8+8tssuu8zLjzvuuCS+5pprvLZwKq2u4AwFABAFBQUAEAUFBQAQRcVdQwmXjj/ooIO8/OGHH07iDRs2FH2cZs2aefnQoUOTeNiwYXlf+8EHHxR9XJTHxIkTy90F3XfffUk8ZcqU8nUE0bz33nt587TwOsny5cuTeNSoUXE7ViacoQAAoqCgAACiqIgpr/333z+JR48e7bV169bNy4899tgkDqem0t92l/wVhg877DCv7aSTTvLyvfbaK4nDb7QuXLjQy2+55Rah7grHWKxVgcMVYn/zm994eXqaa/PmzVGOibor3zfl6yrOUAAAUVBQAABRUFAAAFFUxDWU9Eqr4TWTUPrJe/369fPawtU90yvBFmL16tVePmbMGC8PV4pF3ZJeeVjyn7ooSdddd10Sb7/99nn3ddtttyVxeOtneO0NDdtRRx3l5fmeylhXcYYCAIiCggIAiIKCAgCIoiKe2Lj77rsn8RtvvOG1tW/fvhSH1Jo1a7x8+vTpSfz44497beH3FioNT2xEkXhiYy0Kn+iZvobSrl272u5OTfHERgBA6VBQAABRVMRtw+nbNq+44gqvbeDAgV7eu3fvJJ4/f37O/YTtr732Ws42yX/SGgDENmnSJC9PLzlVX3CGAgCIgoICAIiCggIAiKIirqGkPfvss3lzAKiLPvzwQy/v1atXEnfv3t1r+/jjj2ulT7FxhgIAiIKCAgCIgoICAIii4q6hAEB9NHLkSC8/9dRTk3jRokW13Z2S4AwFABAFBQUAEAVTXgBQC+bMmePlXbp0KVNPSoczFABAFBQUAEAUFBQAQBSFXkNZJmn+VrdCbepU7g5UA+OmMjF2UKwqx05BjwAGACAXprwAAFFQUAAAUVBQAABRUFAAAFFQUAAAUVBQAABRUFAAAFFQUAAAUVBQAABR/B8GNc6Qw2+HZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc119860d50>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "log_interval = 10\n",
    "lr_step_gamma = 0.7\n",
    "momentum = 0.5\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SudokuNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SudokuNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.dropout1 = nn.Dropout2d(0.5)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(64*5*5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv => ReLU => Pool layer\n",
    "        x = self.conv1(x) \n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # Conv => ReLU => Pool layer\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # FC => ReLU layer\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SudokuNet()\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=lr_step_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.3043, Accuracy: 909/10000 (9%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.282156\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.291761\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.292744\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.299986\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.295798\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.296472\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.233459\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.285927\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.239610\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.222324\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.254619\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.262919\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.237945\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.205248\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.267284\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.161996\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.177940\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.207276\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.200973\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.116657\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.250989\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.105464\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.140152\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.148462\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.087496\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.241916\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.166512\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.198802\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.211967\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.080223\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.049899\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.091331\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.002395\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.062103\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.016972\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 1.819717\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.036386\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 1.898091\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 1.933033\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.058628\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.934685\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 1.934576\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.211714\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 2.001017\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 1.928497\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 1.824737\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 1.887926\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 2.028447\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 1.937121\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 1.945501\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.864022\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 1.804231\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 1.826654\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 1.929033\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 1.703275\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 1.931774\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 1.874954\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 1.749902\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 1.929917\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 1.730155\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.905852\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 1.797381\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 1.810041\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 1.810279\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 1.840575\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 1.581832\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 1.600259\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 1.641696\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 1.693855\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 1.877896\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.920203\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 1.742111\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 1.543605\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 1.799886\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 1.728582\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.789346\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 1.852216\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 1.576663\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 1.873666\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 1.691425\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.721336\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 1.865868\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 1.781328\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 1.799535\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 1.715252\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 1.830800\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 2.022675\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 1.514150\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 1.692925\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 1.977161\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.810261\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 1.562114\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 1.563733\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 1.627447\n",
      "\n",
      "Test set: Average loss: 1.3574, Accuracy: 8418/10000 (84%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.791424\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 1.812213\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 1.632270\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 1.725597\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 1.627302\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 1.734048\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 1.585059\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 1.605453\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 1.825652\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 1.754803\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1.755242\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 1.504559\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 1.711605\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 1.566743\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 1.525275\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 1.471257\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 1.580346\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 1.726650\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 1.669619\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 1.563817\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.796243\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 1.579926\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 1.662770\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 1.731691\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 1.609149\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.529180\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 1.536783\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 1.627472\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 1.616214\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 1.701341\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.561163\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 1.625725\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 1.757231\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 1.739560\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 1.608781\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 1.490618\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 1.315441\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 1.481279\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 1.377297\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 1.808014\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.556396\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 1.215940\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 1.558568\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 1.637742\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 1.509061\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 1.784631\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 1.628868\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 1.569434\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 1.596411\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 1.529448\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.477574\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 1.451365\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 1.472381\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 1.739226\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 1.758622\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 1.566567\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 1.558344\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 1.720342\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 1.620617\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 1.472633\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.455656\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 1.428532\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 1.346440\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 1.447612\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 1.252874\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 1.482546\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 1.523300\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 1.616085\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 1.396811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 1.364589\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1.521056\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 1.729441\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 1.449301\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 1.557527\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 1.469815\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.570067\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 1.488552\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 1.452968\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 1.528502\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 1.638929\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.462472\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 1.461021\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 1.607907\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 1.368488\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 1.351241\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 1.490487\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 1.622581\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 1.519265\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 1.477096\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 1.375617\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.529685\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 1.467733\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 1.684544\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 1.651924\n",
      "\n",
      "Test set: Average loss: 1.0110, Accuracy: 9167/10000 (92%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.733325\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 1.431486\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 1.503088\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 1.666081\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 1.509058\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 1.516542\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 1.603721\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 1.586730\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 1.442628\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 1.407758\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.463493\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 1.772169\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.979492\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 1.597842\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 1.328865\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 1.398787\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 1.558127\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 1.589182\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 1.375638\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 1.513964\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.431838\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 1.666060\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 1.289210\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 1.717796\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 1.539258\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.463675\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 1.419350\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 1.556185\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 1.341396\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 1.308230\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.644973\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 1.575689\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 1.292545\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 1.568950\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 1.346796\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 1.669164\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 1.507537\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 1.418190\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 1.381652\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 1.550911\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.391821\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 1.587178\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 1.417607\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 1.554691\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 1.536539\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 1.442464\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 1.479772\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 1.641008\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 1.328518\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 1.514490\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.491551\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 1.688911\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 1.612305\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 1.664923\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 1.535382\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 1.501642\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 1.469983\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 1.410837\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 1.530361\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 1.412131\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.585330\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 1.508508\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 1.409881\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 1.173872\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 1.211737\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 1.493325\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 1.353554\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 1.624923\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 1.386110\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 1.374876\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 1.340100\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 1.434939\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 1.552451\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 1.481223\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 1.566178\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.433883\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 1.438147\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 1.491702\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 1.564768\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 1.393030\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.126962\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 1.430065\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 1.458916\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 1.341440\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 1.210934\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 1.353295\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 1.374146\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 1.326328\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 1.392688\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 1.532298\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 1.757642\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 1.450625\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 1.370568\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 1.388232\n",
      "\n",
      "Test set: Average loss: 0.8556, Accuracy: 9333/10000 (93%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.417323\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 1.428796\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 1.493171\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 1.416513\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 1.467713\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 1.422894\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 1.704136\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 1.274128\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 1.339387\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 1.479846\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 1.281827\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 1.555097\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 1.291559\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 1.483401\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 1.418286\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 1.377367\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 1.358740\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 1.313160\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 1.220737\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 1.366090\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.253616\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 1.353948\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 1.371008\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 1.597838\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 1.593351\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.415944\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 1.668397\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 1.691200\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 1.550595\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 1.490043\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 1.524084\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 1.429914\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 1.464398\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 1.349957\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 1.471705\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 1.452559\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 1.492285\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 1.465680\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 1.490321\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 1.525968\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.421665\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 1.339887\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 1.408167\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 1.398023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 1.431876\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 1.428551\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 1.352257\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 1.476019\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 1.672989\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 1.507587\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.373737\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 1.590548\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 1.513326\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 1.270993\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 1.528187\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 1.235877\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 1.571392\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 1.106328\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 1.429633\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 1.299998\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.376516\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 1.389962\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 1.490934\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 1.304078\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 1.376573\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 1.087928\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 1.565710\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 1.349363\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 1.190269\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 1.472844\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 1.401072\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 1.408460\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 1.455965\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 1.353307\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 1.603192\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1.514181\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 1.455785\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 1.665880\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 1.475618\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 1.371738\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.173449\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 1.342044\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 1.498007\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 1.314624\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 1.149021\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 1.147843\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 1.599379\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 1.512695\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 1.566033\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 1.288241\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 1.457560\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 1.416660\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 1.451489\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 1.461149\n",
      "\n",
      "Test set: Average loss: 0.8146, Accuracy: 9366/10000 (94%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.486164\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 1.421584\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 1.559525\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 1.266543\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 1.346560\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 1.359119\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 1.284923\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 1.222913\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 1.309172\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 1.511492\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 1.520096\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 1.415633\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 1.318875\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 1.482209\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 1.327188\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 1.138476\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 1.766930\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 1.654715\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 1.371631\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 1.519084\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.490475\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 1.239512\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 1.401392\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 1.576266\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 1.361069\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 1.317141\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 1.473826\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 1.362142\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 1.348601\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 1.276121\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 1.414803\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 1.327838\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 1.163151\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 1.612818\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 1.326053\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 1.239318\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 1.334231\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 1.180130\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 1.478959\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 1.549383\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.306505\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 1.626748\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 1.345875\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 1.346740\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 1.155596\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 1.282553\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 1.329632\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 1.549072\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 1.463330\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 1.340911\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.534178\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 1.394376\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 1.283816\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 1.597794\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 1.336297\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 1.294561\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 1.335374\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 1.647130\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 1.344853\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 1.404961\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.352195\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 1.569591\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 1.252665\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 1.344254\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 1.569435\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 1.501280\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 1.552024\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 1.261237\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 1.344394\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 1.557285\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 1.658530\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 1.488977\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.979628\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 1.479440\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 1.414277\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 1.548301\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 1.427678\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 1.543795\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 1.669358\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 1.577797\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.628782\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 1.513909\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 1.324841\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 1.208742\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 1.442539\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 1.567049\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 1.332122\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 1.303140\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 1.558342\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 1.158100\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 1.273477\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 1.425479\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 1.182549\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 1.461314\n",
      "\n",
      "Test set: Average loss: 0.7659, Accuracy: 9415/10000 (94%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.410571\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 1.524289\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 1.546406\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 1.308235\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 1.603871\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 1.331222\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 1.763461\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 1.307721\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 1.354906\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 1.514184\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 1.565028\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 1.576915\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 1.335143\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 1.501217\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 1.294342\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 1.166773\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 1.590356\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 1.255323\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 1.161581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 1.505960\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 1.198422\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 1.158749\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 1.271151\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 1.316133\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 1.130203\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 1.354321\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 1.252366\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 1.420159\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 1.426859\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 1.405662\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 1.384724\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 1.183835\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 1.470183\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 1.392749\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 1.379413\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 1.397606\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 1.197808\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 1.414009\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 1.439131\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 1.339160\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 1.188440\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 1.472511\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 1.354168\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 1.449434\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 1.519755\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 1.430460\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 1.313609\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 1.395341\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 1.463292\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 1.401313\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.289596\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 1.258717\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 1.391440\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 1.297801\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 1.380857\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 1.255051\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 1.477609\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 1.318238\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 1.268045\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 1.568809\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 1.387452\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 1.529370\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 1.627284\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 1.530344\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 1.400190\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 1.428959\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 1.459101\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 1.359638\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 1.688653\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 1.414103\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 1.427024\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 1.273071\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 1.383323\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 1.378955\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 1.306483\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 1.114084\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 1.422887\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 1.338898\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 1.523609\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 1.236525\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 1.711689\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 1.387566\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 1.425167\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 1.368309\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 1.344230\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 1.288745\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 1.432538\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 1.622291\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 1.203935\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 1.305791\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 1.576120\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 1.577189\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 1.660604\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 1.430790\n",
      "\n",
      "Test set: Average loss: 0.7451, Accuracy: 9417/10000 (94%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.323040\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 1.429571\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 1.434498\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 1.544193\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 1.401094\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 1.219760\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 1.455098\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 1.819371\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 1.661282\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 1.332522\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 1.257725\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 1.298730\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 1.209655\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 1.312911\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 1.473185\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 1.200832\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 1.460672\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 1.314522\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 1.362043\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 1.349449\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 1.522718\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 1.569606\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 1.383943\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 1.327237\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 1.422203\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 1.672133\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 1.549483\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 1.283406\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 1.201134\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 1.315451\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 1.350819\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 1.437648\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 1.738735\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 1.538197\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 1.454641\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 1.234746\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 1.554595\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 1.569606\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 1.231585\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 1.326928\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 1.565417\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 1.544229\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 1.533964\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 1.398671\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 1.438702\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 1.177432\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 1.614637\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 1.402163\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 1.454608\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 1.306034\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 1.367130\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 1.528249\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 1.376589\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 1.587735\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 1.458512\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 1.306666\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 1.367193\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 1.421523\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 1.363548\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 1.457640\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 1.151117\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 1.413800\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 1.224893\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 1.360072\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 1.340031\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 1.296261\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 1.496396\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 1.226769\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 1.520006\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 1.583767\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 1.451720\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 1.344548\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 1.304126\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 1.319805\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 1.369026\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 1.126711\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 1.482698\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 1.561576\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 1.445623\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 1.379981\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 1.242352\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 1.289798\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 1.507409\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 1.531789\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 1.321603\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 1.091046\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 1.362142\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 1.299308\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 1.296792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 1.587174\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 1.338119\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 1.445041\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 1.428178\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 1.354140\n",
      "\n",
      "Test set: Average loss: 0.7248, Accuracy: 9436/10000 (94%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.434707\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 1.331959\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 1.529317\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 1.274302\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 1.279877\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 1.333439\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 1.579588\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 1.218261\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 1.151576\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 1.474490\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 1.568484\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 1.575773\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 1.531906\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 1.190265\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 1.338739\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 1.459822\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 1.387424\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 1.275448\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 1.298205\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 1.231245\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 1.253103\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 1.508659\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 1.365671\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 1.491034\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 1.350735\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 1.459139\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 1.555103\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 1.190937\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 1.398693\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 1.649083\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 1.161106\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 1.235303\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 1.560017\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 1.575327\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 1.619415\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 1.420643\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 1.475696\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 1.400106\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 1.323042\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 1.284102\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 1.399847\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 1.361577\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 1.507679\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 1.679616\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 1.409435\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 1.615723\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 1.545906\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 1.576857\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 1.366486\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 1.329743\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 1.347783\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 1.481369\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 1.342654\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 1.314493\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 1.246720\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 1.423624\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 1.640348\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 1.150553\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 1.480368\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 1.316009\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 1.083773\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 1.298203\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 1.107812\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 1.180492\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 1.501560\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 1.093591\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 1.368911\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 1.559632\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 1.412402\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 1.443005\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 1.487564\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 1.216345\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 1.315543\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 1.386238\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 1.320305\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 1.199881\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 1.341233\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 1.409650\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 1.477312\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 1.538623\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 1.542665\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 1.299107\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 1.247156\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 1.156624\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 1.275948\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 1.517375\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 1.250583\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 1.170548\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 1.482016\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 1.231192\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 1.203695\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 1.342618\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 1.297573\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 1.247946\n",
      "\n",
      "Test set: Average loss: 0.7085, Accuracy: 9453/10000 (95%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.356008\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 1.549232\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 1.373903\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 1.452204\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 1.613444\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 1.622354\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 1.576764\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 1.212094\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 1.305269\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 1.451896\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 1.341636\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 1.412153\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 1.413316\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 1.248205\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 1.268299\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 1.557505\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 1.393060\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 1.498753\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 1.302230\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 1.375125\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 1.334930\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 1.124225\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 1.434525\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 1.161153\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 1.460922\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 1.140926\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 1.122656\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 1.478179\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 1.405303\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 1.700763\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 1.280541\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 1.148333\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 1.425284\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 1.288497\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 1.481988\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 1.540520\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 1.476037\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 1.338702\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 1.242413\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 1.262092\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 1.424639\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 1.286459\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 1.420417\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 1.403649\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 1.307543\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 1.443941\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 1.538307\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 1.326979\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 1.119509\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 1.497078\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 1.423729\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 1.406767\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 1.550248\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 1.164258\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 1.270384\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 1.357897\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 1.628504\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 1.452351\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 1.273688\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 1.466544\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 1.310722\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 1.265078\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 1.109399\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 1.299022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 1.610161\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 1.542165\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 1.516393\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 1.354686\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 1.428142\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 1.402426\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 1.186405\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 1.329875\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 1.588999\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 1.334479\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 1.641502\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 1.267416\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 1.624196\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 1.374202\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 1.388175\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 1.515211\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 1.504789\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 1.162263\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 1.536876\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 1.184684\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 1.095284\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 1.367799\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 1.563841\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 1.624195\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 1.219191\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 1.337420\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 1.282233\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 1.475282\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 1.372677\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 1.059318\n",
      "\n",
      "Test set: Average loss: 0.7059, Accuracy: 9457/10000 (95%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.771455\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 1.540037\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 1.178683\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 1.321007\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 1.554436\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 1.324800\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 1.490534\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 1.044923\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 1.254385\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 1.524237\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 1.382970\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 1.316036\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 1.265137\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 1.772354\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 1.205921\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 1.275680\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 1.320638\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 1.294058\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 1.386981\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 1.377367\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 1.415613\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 1.449239\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 1.305863\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 1.524347\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 1.384432\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 1.470003\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 1.607751\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 1.572294\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 1.451671\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 1.512715\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 1.506389\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 1.327227\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 1.562670\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 1.191954\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 1.337766\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 1.380289\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 1.437983\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 1.243502\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 1.507577\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 1.404241\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 1.580755\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 1.319768\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 1.472557\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 1.345267\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 1.578341\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 1.408388\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 1.389659\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 1.455837\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 1.364851\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 1.242538\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 1.330536\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 1.385599\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 1.258147\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 1.478439\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 1.528875\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 1.203512\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 1.406853\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 1.497566\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 1.424453\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 1.279695\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 1.026806\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 1.355221\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 1.441625\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 1.465577\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 1.140806\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 1.151760\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 1.479774\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 1.411256\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 1.349776\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 1.309488\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 1.476671\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 1.300565\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 1.457850\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 1.137215\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 1.442155\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 1.347837\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 1.428507\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 1.323174\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 1.450794\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 1.397301\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 1.456841\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 1.447479\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 1.418767\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 1.598339\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 1.634886\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 1.254878\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 1.097947\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 1.299184\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 1.351270\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 1.168957\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 1.184060\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 1.393639\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 1.346704\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 1.531324\n",
      "\n",
      "Test set: Average loss: 0.7012, Accuracy: 9462/10000 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adadelta(model.parameters(), lr=0.01)\n",
    "\n",
    "test(model, device, test_loader)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=lr_step_gamma)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(example_data)\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Prediction: {}\".format(output.data.max(1, keepdim=True)[1][i].item()))\n",
    "    plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "print(output.data.max(1,True)[1][0].item())\n",
    "print(output.data.max(1,True)[1][1].item())\n",
    "print(output.data.max(1,True)[1][2].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/kosuke/miniconda3/envs/source_cv4_py36/bin/../lib/libfontconfig.so.1: undefined symbol: FT_Done_MM_Var",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-234-fde3188bf0da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./test_data/test_cell1.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/kosuke/miniconda3/envs/source_cv4_py36/bin/../lib/libfontconfig.so.1: undefined symbol: FT_Done_MM_Var"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "\n",
    "image = cv2.imread(\"./test_data/test_cell1.jpg\")\n",
    "# roi = cv2.resize(image, (28, 28))\n",
    "# roi = roi.astype(\"float\") / 255.0\n",
    "# roi = img_to_array(roi)\n",
    "# print(roi)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep to save the model to be used in C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([32, 1, 5, 5])\n",
      "conv1.bias \t torch.Size([32])\n",
      "conv2.weight \t torch.Size([64, 32, 3, 3])\n",
      "conv2.bias \t torch.Size([64])\n",
      "fc1.weight \t torch.Size([128, 1600])\n",
      "fc1.bias \t torch.Size([128])\n",
      "fc2.weight \t torch.Size([10, 128])\n",
      "fc2.bias \t torch.Size([10])\n",
      "Optimizer's state_dict:\n",
      "state \t {140466598930328: {'step': 4690, 'square_avg': tensor([[[[4.3341e-05, 3.8368e-05, 6.2752e-05, 6.4492e-05, 2.4329e-05],\n",
      "          [6.5469e-05, 7.9749e-05, 1.0045e-04, 6.3590e-05, 3.5428e-05],\n",
      "          [9.5182e-05, 1.1238e-04, 1.2895e-04, 8.8450e-05, 7.3660e-05],\n",
      "          [6.8761e-05, 7.0515e-05, 5.3159e-05, 5.4676e-05, 7.5723e-05],\n",
      "          [5.8572e-05, 5.0048e-05, 4.0376e-05, 3.9879e-05, 4.8963e-05]]],\n",
      "\n",
      "\n",
      "        [[[3.2676e-05, 6.9174e-05, 6.6171e-05, 3.4924e-05, 2.4718e-05],\n",
      "          [3.9216e-05, 8.3439e-05, 4.3531e-05, 2.3949e-05, 1.6864e-05],\n",
      "          [5.2054e-05, 6.1873e-05, 3.3731e-05, 2.9840e-05, 3.0642e-05],\n",
      "          [6.2428e-05, 5.4302e-05, 3.1562e-05, 2.3293e-05, 2.2394e-05],\n",
      "          [5.0121e-05, 4.0753e-05, 2.4935e-05, 1.7783e-05, 1.7001e-05]]],\n",
      "\n",
      "\n",
      "        [[[7.5784e-06, 1.4044e-05, 1.6320e-05, 1.8935e-05, 2.2142e-05],\n",
      "          [3.0530e-05, 3.5209e-05, 2.7484e-05, 3.1727e-05, 2.8891e-05],\n",
      "          [4.7328e-05, 4.7627e-05, 4.1202e-05, 3.2693e-05, 2.2062e-05],\n",
      "          [3.9798e-05, 4.2648e-05, 3.2675e-05, 2.0914e-05, 7.7586e-06],\n",
      "          [3.7655e-05, 2.9216e-05, 3.1704e-05, 1.9737e-05, 1.2180e-05]]],\n",
      "\n",
      "\n",
      "        [[[1.6333e-05, 2.0538e-05, 2.4438e-05, 2.6875e-05, 7.5443e-05],\n",
      "          [7.8385e-06, 1.0609e-05, 1.4502e-05, 5.3607e-05, 9.0298e-05],\n",
      "          [6.5610e-06, 1.3317e-05, 3.2168e-05, 8.3125e-05, 7.3693e-05],\n",
      "          [2.0724e-05, 2.7111e-05, 5.8633e-05, 7.5457e-05, 2.9420e-05],\n",
      "          [2.2043e-05, 4.3763e-05, 8.8479e-05, 5.1221e-05, 2.0001e-05]]],\n",
      "\n",
      "\n",
      "        [[[3.8955e-05, 3.8906e-05, 1.0372e-04, 8.8137e-05, 6.9932e-05],\n",
      "          [2.4968e-05, 6.2885e-05, 9.8564e-05, 6.6501e-05, 5.4083e-05],\n",
      "          [6.6287e-05, 1.0550e-04, 9.1856e-05, 3.5852e-05, 3.1482e-05],\n",
      "          [9.0083e-05, 1.0951e-04, 5.3422e-05, 1.9168e-05, 1.6986e-05],\n",
      "          [6.8851e-05, 8.8393e-05, 5.2888e-05, 2.8745e-05, 3.0964e-05]]],\n",
      "\n",
      "\n",
      "        [[[2.8499e-05, 2.5879e-05, 3.9632e-05, 8.7294e-05, 6.8675e-05],\n",
      "          [4.5347e-05, 4.4617e-05, 8.1296e-05, 8.8772e-05, 4.7495e-05],\n",
      "          [6.5564e-05, 6.8735e-05, 8.6336e-05, 7.8821e-05, 3.1124e-05],\n",
      "          [3.1621e-05, 4.3221e-05, 8.1185e-05, 4.6059e-05, 2.5289e-05],\n",
      "          [2.3659e-05, 4.4222e-05, 6.9474e-05, 2.6988e-05, 3.0558e-05]]],\n",
      "\n",
      "\n",
      "        [[[1.9617e-05, 1.2673e-05, 9.7168e-06, 1.1679e-05, 1.1891e-05],\n",
      "          [1.4806e-05, 7.7982e-06, 1.3819e-05, 1.9834e-05, 1.1977e-05],\n",
      "          [1.3613e-05, 1.6904e-05, 2.2132e-05, 2.1474e-05, 1.1081e-05],\n",
      "          [3.3905e-05, 3.4015e-05, 3.4234e-05, 2.7769e-05, 2.9391e-05],\n",
      "          [5.5557e-05, 7.7871e-05, 8.2524e-05, 9.9735e-05, 1.0045e-04]]],\n",
      "\n",
      "\n",
      "        [[[1.7429e-05, 1.4787e-05, 1.6251e-05, 1.2973e-05, 1.9785e-05],\n",
      "          [2.6835e-05, 1.7451e-05, 9.4329e-06, 1.1390e-05, 2.3239e-05],\n",
      "          [4.4085e-05, 1.7217e-05, 9.3650e-06, 2.6086e-05, 2.8121e-05],\n",
      "          [4.6161e-05, 2.1482e-05, 1.3652e-05, 3.9855e-05, 3.6562e-05],\n",
      "          [2.8351e-05, 1.8229e-05, 5.0877e-05, 5.6964e-05, 2.6218e-05]]],\n",
      "\n",
      "\n",
      "        [[[2.7625e-05, 1.7859e-05, 2.2826e-05, 3.1385e-05, 4.4028e-05],\n",
      "          [3.1588e-05, 2.3268e-05, 2.2925e-05, 3.6864e-05, 3.2976e-05],\n",
      "          [3.0646e-05, 3.2189e-05, 3.1391e-05, 3.6731e-05, 4.2097e-05],\n",
      "          [5.8693e-05, 4.9661e-05, 3.5249e-05, 3.6814e-05, 4.6048e-05],\n",
      "          [6.9519e-05, 6.0448e-05, 4.4121e-05, 3.5271e-05, 4.5834e-05]]],\n",
      "\n",
      "\n",
      "        [[[2.5583e-05, 4.4216e-05, 7.9302e-05, 9.7449e-05, 6.7734e-05],\n",
      "          [3.5378e-05, 3.7613e-05, 5.1284e-05, 4.4857e-05, 3.1258e-05],\n",
      "          [1.8540e-05, 1.8203e-05, 2.3460e-05, 1.8328e-05, 2.7148e-05],\n",
      "          [1.0147e-05, 1.4701e-05, 2.1948e-05, 3.1150e-05, 3.1185e-05],\n",
      "          [1.2957e-05, 1.8501e-05, 1.9592e-05, 2.5898e-05, 3.4121e-05]]],\n",
      "\n",
      "\n",
      "        [[[3.9075e-05, 3.1079e-05, 4.6395e-05, 4.9907e-05, 4.0128e-05],\n",
      "          [2.8381e-05, 3.1956e-05, 2.9939e-05, 2.8270e-05, 1.9722e-05],\n",
      "          [3.6914e-05, 4.0161e-05, 3.7586e-05, 3.0512e-05, 4.0357e-05],\n",
      "          [4.7556e-05, 4.4917e-05, 3.7492e-05, 3.6921e-05, 3.1981e-05],\n",
      "          [8.4665e-05, 6.1531e-05, 3.3169e-05, 3.2676e-05, 3.7453e-05]]],\n",
      "\n",
      "\n",
      "        [[[8.2087e-06, 1.1343e-05, 1.9319e-05, 3.1359e-05, 2.7283e-05],\n",
      "          [1.4123e-05, 1.3355e-05, 2.3677e-05, 3.2989e-05, 3.5634e-05],\n",
      "          [1.5489e-05, 1.0765e-05, 2.9016e-05, 3.5972e-05, 3.6364e-05],\n",
      "          [1.4575e-05, 2.1338e-05, 4.1024e-05, 3.3511e-05, 1.8750e-05],\n",
      "          [1.7686e-05, 2.7345e-05, 4.0226e-05, 2.2365e-05, 1.1985e-05]]],\n",
      "\n",
      "\n",
      "        [[[2.0697e-05, 1.6950e-05, 2.0486e-05, 2.9088e-05, 7.3746e-05],\n",
      "          [2.2329e-05, 1.9570e-05, 2.5381e-05, 6.0298e-05, 1.3452e-04],\n",
      "          [2.1633e-05, 2.0698e-05, 3.6963e-05, 9.1458e-05, 1.4819e-04],\n",
      "          [2.3484e-05, 2.2641e-05, 7.0704e-05, 1.5461e-04, 1.3693e-04],\n",
      "          [2.6924e-05, 4.1492e-05, 9.1022e-05, 1.3550e-04, 1.1754e-04]]],\n",
      "\n",
      "\n",
      "        [[[5.0899e-06, 5.6525e-06, 1.2150e-05, 9.0476e-06, 8.4313e-06],\n",
      "          [1.1845e-05, 1.1779e-05, 1.4175e-05, 9.8556e-06, 6.4962e-06],\n",
      "          [8.0879e-06, 4.2161e-06, 5.5954e-06, 9.7956e-06, 6.6906e-06],\n",
      "          [3.9227e-06, 3.4678e-06, 3.6809e-06, 5.3300e-06, 5.2682e-06],\n",
      "          [2.7590e-06, 3.6622e-06, 3.9712e-06, 3.0401e-06, 4.0458e-06]]],\n",
      "\n",
      "\n",
      "        [[[8.2644e-05, 8.0436e-05, 7.3231e-05, 5.4952e-05, 5.2616e-05],\n",
      "          [8.7889e-05, 6.3912e-05, 5.4285e-05, 4.4023e-05, 3.6324e-05],\n",
      "          [6.0910e-05, 3.4677e-05, 3.0238e-05, 3.3110e-05, 5.1490e-05],\n",
      "          [3.9857e-05, 2.8422e-05, 3.7709e-05, 4.7940e-05, 4.6662e-05],\n",
      "          [3.8008e-05, 4.5061e-05, 4.6747e-05, 5.5074e-05, 4.9828e-05]]],\n",
      "\n",
      "\n",
      "        [[[7.1232e-05, 1.0543e-04, 1.2802e-04, 9.1526e-05, 5.6926e-05],\n",
      "          [7.8961e-05, 1.0949e-04, 1.3316e-04, 8.6277e-05, 3.3982e-05],\n",
      "          [6.8411e-05, 7.4600e-05, 7.6015e-05, 3.5895e-05, 5.5040e-05],\n",
      "          [5.9591e-05, 6.7914e-05, 6.1328e-05, 3.3688e-05, 6.0962e-05],\n",
      "          [6.8630e-05, 5.9526e-05, 3.9667e-05, 3.8692e-05, 3.6424e-05]]],\n",
      "\n",
      "\n",
      "        [[[6.8735e-06, 8.0431e-06, 9.2960e-06, 4.9630e-06, 1.0514e-05],\n",
      "          [6.4731e-06, 8.9274e-06, 1.3204e-05, 1.4219e-05, 2.3553e-05],\n",
      "          [1.4006e-05, 2.9049e-05, 4.1505e-05, 2.9320e-05, 2.8960e-05],\n",
      "          [2.4158e-05, 5.1317e-05, 7.9687e-05, 5.8269e-05, 6.4356e-05],\n",
      "          [1.7594e-05, 5.5208e-05, 9.6056e-05, 1.1064e-04, 7.8207e-05]]],\n",
      "\n",
      "\n",
      "        [[[3.7309e-05, 3.1451e-05, 3.1788e-05, 5.6060e-05, 4.8342e-05],\n",
      "          [3.4472e-05, 4.0087e-05, 5.7324e-05, 7.4952e-05, 5.5224e-05],\n",
      "          [3.9946e-05, 7.9252e-05, 1.3419e-04, 1.2878e-04, 9.9736e-05],\n",
      "          [6.3096e-05, 1.2925e-04, 1.0069e-04, 9.6309e-05, 4.8668e-05],\n",
      "          [7.7322e-05, 9.9720e-05, 7.5752e-05, 5.3692e-05, 4.7193e-05]]],\n",
      "\n",
      "\n",
      "        [[[3.6127e-05, 5.2572e-05, 5.4491e-05, 4.1922e-05, 2.7818e-05],\n",
      "          [4.5109e-05, 2.9108e-05, 2.7664e-05, 2.4914e-05, 2.1564e-05],\n",
      "          [5.1499e-05, 3.9237e-05, 5.8816e-05, 4.2348e-05, 4.4871e-05],\n",
      "          [3.5211e-05, 2.6492e-05, 4.2929e-05, 3.9973e-05, 4.2790e-05],\n",
      "          [2.2234e-05, 2.2734e-05, 3.3088e-05, 3.6781e-05, 3.6311e-05]]],\n",
      "\n",
      "\n",
      "        [[[5.5367e-05, 4.0867e-05, 2.7344e-05, 2.1563e-05, 2.6505e-05],\n",
      "          [3.7594e-05, 2.1453e-05, 2.9374e-05, 5.1043e-05, 4.1516e-05],\n",
      "          [4.4525e-05, 4.2675e-05, 5.7720e-05, 4.9037e-05, 2.9691e-05],\n",
      "          [4.8127e-05, 6.3127e-05, 5.7114e-05, 3.1875e-05, 2.8891e-05],\n",
      "          [4.7161e-05, 4.3492e-05, 3.5149e-05, 3.8573e-05, 3.3943e-05]]],\n",
      "\n",
      "\n",
      "        [[[9.1531e-06, 1.0927e-05, 6.8013e-06, 1.1011e-05, 3.6850e-05],\n",
      "          [1.2719e-05, 1.4916e-05, 7.8771e-06, 1.1169e-05, 6.2736e-05],\n",
      "          [1.3908e-05, 1.6311e-05, 5.9601e-06, 2.4819e-05, 9.1728e-05],\n",
      "          [1.3376e-05, 1.3091e-05, 4.4270e-06, 5.4768e-05, 8.9195e-05],\n",
      "          [2.0382e-05, 1.2169e-05, 2.9743e-05, 6.4179e-05, 6.6964e-05]]],\n",
      "\n",
      "\n",
      "        [[[1.8657e-05, 3.7226e-05, 4.6508e-05, 2.2834e-05, 1.0330e-05],\n",
      "          [3.6695e-05, 7.0415e-05, 6.6354e-05, 2.9238e-05, 1.5984e-05],\n",
      "          [7.2502e-05, 6.8835e-05, 4.0322e-05, 1.8777e-05, 1.7517e-05],\n",
      "          [8.7857e-05, 3.2400e-05, 1.1952e-05, 1.2082e-05, 1.3124e-05],\n",
      "          [4.6227e-05, 1.4066e-05, 1.8205e-05, 1.6053e-05, 1.2918e-05]]],\n",
      "\n",
      "\n",
      "        [[[2.1281e-05, 1.6379e-05, 9.6056e-06, 3.7416e-06, 3.8759e-06],\n",
      "          [2.4712e-05, 1.3359e-05, 5.1548e-06, 3.9931e-06, 3.7628e-06],\n",
      "          [1.8859e-05, 5.0046e-06, 3.1498e-06, 3.6007e-06, 2.6579e-06],\n",
      "          [1.5073e-05, 2.9479e-06, 3.5498e-06, 4.0079e-06, 3.1130e-06],\n",
      "          [9.7590e-06, 3.2343e-06, 3.7822e-06, 4.1091e-06, 3.5755e-06]]],\n",
      "\n",
      "\n",
      "        [[[1.9044e-05, 1.8993e-05, 2.1723e-05, 2.7879e-05, 4.0743e-05],\n",
      "          [3.1863e-05, 2.5292e-05, 1.5514e-05, 3.4615e-05, 4.9036e-05],\n",
      "          [2.6763e-05, 2.1118e-05, 3.4052e-05, 5.4151e-05, 3.5839e-05],\n",
      "          [2.9360e-05, 2.8401e-05, 4.3244e-05, 4.4333e-05, 3.0728e-05],\n",
      "          [5.0137e-05, 2.5506e-05, 3.6779e-05, 4.0017e-05, 3.3984e-05]]],\n",
      "\n",
      "\n",
      "        [[[4.4436e-05, 4.4998e-05, 4.1734e-05, 5.2231e-05, 5.6503e-05],\n",
      "          [5.8126e-05, 4.6000e-05, 3.2265e-05, 3.3722e-05, 3.7824e-05],\n",
      "          [5.0593e-05, 2.9666e-05, 3.6745e-05, 3.4567e-05, 3.7438e-05],\n",
      "          [5.4681e-05, 2.7606e-05, 2.9040e-05, 5.0228e-05, 5.4577e-05],\n",
      "          [3.6806e-05, 2.3359e-05, 3.3289e-05, 5.1611e-05, 4.7151e-05]]],\n",
      "\n",
      "\n",
      "        [[[5.0713e-05, 5.2382e-05, 4.2965e-05, 3.1144e-05, 3.6129e-05],\n",
      "          [6.1785e-05, 4.3170e-05, 3.0068e-05, 1.8334e-05, 2.8178e-05],\n",
      "          [4.9232e-05, 3.4752e-05, 3.4444e-05, 2.3271e-05, 2.5086e-05],\n",
      "          [3.2004e-05, 2.8053e-05, 3.8030e-05, 4.5058e-05, 5.1127e-05],\n",
      "          [2.9252e-05, 3.3598e-05, 5.3318e-05, 3.8137e-05, 3.3979e-05]]],\n",
      "\n",
      "\n",
      "        [[[6.7758e-06, 4.2616e-06, 5.4078e-06, 4.0115e-06, 3.9207e-06],\n",
      "          [3.7076e-06, 6.6089e-06, 9.5801e-06, 6.6144e-06, 4.7512e-06],\n",
      "          [3.8586e-06, 8.9727e-06, 8.9832e-06, 3.5204e-06, 1.8985e-06],\n",
      "          [5.2892e-06, 6.4867e-06, 3.9861e-06, 2.3748e-06, 3.6494e-06],\n",
      "          [8.0608e-06, 5.5340e-06, 4.4922e-06, 4.7097e-06, 7.8004e-06]]],\n",
      "\n",
      "\n",
      "        [[[1.7633e-05, 5.1714e-06, 2.8845e-06, 3.7528e-06, 4.5965e-06],\n",
      "          [1.2942e-05, 4.8669e-06, 2.6480e-06, 3.6446e-06, 4.4761e-06],\n",
      "          [4.2077e-06, 3.4234e-06, 3.1225e-06, 3.7346e-06, 3.6324e-06],\n",
      "          [4.7117e-06, 3.1403e-06, 3.9152e-06, 3.2870e-06, 8.2045e-06],\n",
      "          [2.9111e-06, 4.9863e-06, 1.1536e-05, 2.5478e-05, 3.5017e-05]]],\n",
      "\n",
      "\n",
      "        [[[4.2078e-05, 4.8507e-05, 7.2232e-05, 8.6481e-05, 8.2368e-05],\n",
      "          [6.1128e-05, 7.0694e-05, 1.1622e-04, 8.5089e-05, 6.2544e-05],\n",
      "          [7.2576e-05, 8.3916e-05, 1.2811e-04, 4.8480e-05, 3.0652e-05],\n",
      "          [4.8223e-05, 6.8619e-05, 8.5440e-05, 4.6062e-05, 2.5845e-05],\n",
      "          [5.3507e-05, 8.2552e-05, 6.4445e-05, 3.3039e-05, 2.5895e-05]]],\n",
      "\n",
      "\n",
      "        [[[3.5379e-05, 5.4041e-05, 7.0959e-05, 6.2438e-05, 4.9037e-05],\n",
      "          [3.9258e-05, 5.0969e-05, 4.4201e-05, 4.7053e-05, 3.8587e-05],\n",
      "          [4.3416e-05, 5.6464e-05, 4.9297e-05, 5.1286e-05, 3.5711e-05],\n",
      "          [2.4142e-05, 4.0545e-05, 7.3066e-05, 7.2754e-05, 4.0858e-05],\n",
      "          [2.8508e-05, 6.5861e-05, 1.0282e-04, 7.4236e-05, 4.6100e-05]]],\n",
      "\n",
      "\n",
      "        [[[4.9054e-05, 6.4513e-05, 7.0492e-05, 4.7600e-05, 3.8386e-05],\n",
      "          [7.4833e-05, 8.9189e-05, 7.8995e-05, 5.3921e-05, 4.1266e-05],\n",
      "          [5.6848e-05, 4.3342e-05, 4.7352e-05, 3.4946e-05, 6.0883e-05],\n",
      "          [3.4402e-05, 2.8712e-05, 3.7014e-05, 5.4537e-05, 8.7488e-05],\n",
      "          [3.0642e-05, 2.2014e-05, 4.3615e-05, 7.8865e-05, 1.0414e-04]]],\n",
      "\n",
      "\n",
      "        [[[5.8304e-06, 9.4761e-06, 1.4572e-05, 2.7211e-05, 3.4869e-05],\n",
      "          [6.0413e-06, 1.1423e-05, 1.0232e-05, 2.0951e-05, 3.2129e-05],\n",
      "          [6.9875e-06, 4.7934e-06, 1.2866e-05, 3.7649e-05, 6.0407e-05],\n",
      "          [1.0622e-05, 1.8672e-05, 5.0525e-05, 7.4898e-05, 6.4225e-05],\n",
      "          [5.2205e-05, 8.2211e-05, 8.3655e-05, 6.1658e-05, 3.3989e-05]]]]), 'acc_delta': tensor([[[[4.7810e-06, 5.6632e-06, 6.3931e-06, 6.2377e-06, 4.5956e-06],\n",
      "          [5.6763e-06, 5.4639e-06, 7.2601e-06, 5.4790e-06, 4.0134e-06],\n",
      "          [6.4960e-06, 7.0761e-06, 8.2877e-06, 6.7302e-06, 7.1178e-06],\n",
      "          [7.8703e-06, 7.9622e-06, 5.8847e-06, 6.0815e-06, 8.5544e-06],\n",
      "          [7.2920e-06, 5.2068e-06, 4.6942e-06, 4.9589e-06, 9.4563e-06]]],\n",
      "\n",
      "\n",
      "        [[[3.5332e-06, 5.6924e-06, 6.6777e-06, 4.7445e-06, 3.6674e-06],\n",
      "          [4.4638e-06, 6.9819e-06, 4.9744e-06, 3.7648e-06, 3.9579e-06],\n",
      "          [5.2983e-06, 4.5812e-06, 3.6364e-06, 4.3600e-06, 5.9878e-06],\n",
      "          [5.6461e-06, 4.0044e-06, 3.7250e-06, 4.3279e-06, 4.6679e-06],\n",
      "          [4.8992e-06, 4.3442e-06, 3.4353e-06, 4.0904e-06, 3.7271e-06]]],\n",
      "\n",
      "\n",
      "        [[[2.8604e-06, 4.7033e-06, 4.6041e-06, 4.8584e-06, 4.6027e-06],\n",
      "          [5.2062e-06, 7.4421e-06, 5.5953e-06, 7.6985e-06, 6.3335e-06],\n",
      "          [7.4125e-06, 7.4734e-06, 6.8357e-06, 7.6370e-06, 5.9942e-06],\n",
      "          [6.8233e-06, 6.0530e-06, 5.9845e-06, 4.8254e-06, 2.5570e-06],\n",
      "          [5.6927e-06, 5.0366e-06, 5.8091e-06, 4.4633e-06, 2.3517e-06]]],\n",
      "\n",
      "\n",
      "        [[[6.6630e-06, 6.3470e-06, 4.9906e-06, 3.9050e-06, 6.7458e-06],\n",
      "          [3.6522e-06, 4.7257e-06, 3.7301e-06, 6.0391e-06, 7.2995e-06],\n",
      "          [3.5050e-06, 4.7796e-06, 4.8097e-06, 6.7849e-06, 6.0481e-06],\n",
      "          [5.2435e-06, 6.3972e-06, 5.9362e-06, 5.8465e-06, 3.1852e-06],\n",
      "          [6.6558e-06, 5.6979e-06, 7.0994e-06, 4.6002e-06, 2.4887e-06]]],\n",
      "\n",
      "\n",
      "        [[[4.0068e-06, 3.2513e-06, 7.6428e-06, 7.0004e-06, 8.1337e-06],\n",
      "          [2.5745e-06, 5.4983e-06, 7.4646e-06, 7.0729e-06, 7.6470e-06],\n",
      "          [7.2126e-06, 9.0221e-06, 9.7139e-06, 6.5569e-06, 5.5657e-06],\n",
      "          [8.3761e-06, 8.4234e-06, 5.8074e-06, 5.1093e-06, 4.2939e-06],\n",
      "          [6.7774e-06, 7.5587e-06, 5.6249e-06, 5.4171e-06, 6.0181e-06]]],\n",
      "\n",
      "\n",
      "        [[[5.1520e-06, 4.2139e-06, 6.5671e-06, 1.0813e-05, 9.9697e-06],\n",
      "          [7.5198e-06, 4.9997e-06, 6.7907e-06, 9.4231e-06, 8.0812e-06],\n",
      "          [6.6836e-06, 6.0363e-06, 7.1231e-06, 8.3901e-06, 6.3351e-06],\n",
      "          [5.2071e-06, 5.4333e-06, 7.9111e-06, 5.4151e-06, 5.4277e-06],\n",
      "          [3.9615e-06, 5.3818e-06, 5.5524e-06, 3.5039e-06, 5.0289e-06]]],\n",
      "\n",
      "\n",
      "        [[[5.3851e-06, 3.4865e-06, 2.4541e-06, 3.5325e-06, 4.3456e-06],\n",
      "          [5.2812e-06, 2.8092e-06, 2.9029e-06, 4.2621e-06, 3.5202e-06],\n",
      "          [4.5124e-06, 4.7827e-06, 4.2494e-06, 4.3207e-06, 3.1271e-06],\n",
      "          [3.8063e-06, 3.5541e-06, 3.3445e-06, 3.2823e-06, 4.0302e-06],\n",
      "          [5.3485e-06, 6.3861e-06, 5.9152e-06, 5.2978e-06, 6.5231e-06]]],\n",
      "\n",
      "\n",
      "        [[[3.8938e-06, 3.7394e-06, 5.2290e-06, 5.4784e-06, 5.8570e-06],\n",
      "          [5.9532e-06, 5.4928e-06, 4.3114e-06, 5.0757e-06, 6.9471e-06],\n",
      "          [7.4404e-06, 4.9946e-06, 3.8299e-06, 9.0699e-06, 6.1261e-06],\n",
      "          [8.3526e-06, 5.0470e-06, 5.0677e-06, 6.9697e-06, 5.1091e-06],\n",
      "          [6.0862e-06, 4.0378e-06, 7.6997e-06, 6.6314e-06, 5.1576e-06]]],\n",
      "\n",
      "\n",
      "        [[[6.0361e-06, 4.8637e-06, 4.5594e-06, 5.1897e-06, 7.5511e-06],\n",
      "          [6.4390e-06, 5.1032e-06, 3.9945e-06, 5.1706e-06, 4.7941e-06],\n",
      "          [5.3736e-06, 5.2077e-06, 4.2789e-06, 4.6110e-06, 6.1033e-06],\n",
      "          [6.6705e-06, 6.5790e-06, 5.8028e-06, 6.1331e-06, 8.9903e-06],\n",
      "          [7.1888e-06, 6.8340e-06, 5.4923e-06, 4.4170e-06, 7.9560e-06]]],\n",
      "\n",
      "\n",
      "        [[[3.6883e-06, 4.7787e-06, 6.3551e-06, 6.6277e-06, 5.0085e-06],\n",
      "          [4.3553e-06, 3.9230e-06, 4.3320e-06, 3.9914e-06, 4.6775e-06],\n",
      "          [2.9543e-06, 2.9351e-06, 4.2199e-06, 4.4895e-06, 7.1661e-06],\n",
      "          [2.7792e-06, 3.6292e-06, 5.7425e-06, 6.8025e-06, 7.8539e-06],\n",
      "          [3.9525e-06, 5.1618e-06, 5.5671e-06, 4.9726e-06, 7.8490e-06]]],\n",
      "\n",
      "\n",
      "        [[[5.8254e-06, 4.5845e-06, 6.1023e-06, 7.3875e-06, 7.5445e-06],\n",
      "          [4.8658e-06, 4.3341e-06, 4.6081e-06, 5.0639e-06, 3.4976e-06],\n",
      "          [6.1661e-06, 6.3941e-06, 7.0806e-06, 5.4553e-06, 5.4948e-06],\n",
      "          [6.3519e-06, 4.9364e-06, 5.4807e-06, 5.8787e-06, 5.3292e-06],\n",
      "          [5.9124e-06, 4.6094e-06, 4.8504e-06, 4.8775e-06, 6.6565e-06]]],\n",
      "\n",
      "\n",
      "        [[[3.1403e-06, 4.1230e-06, 4.7323e-06, 5.4529e-06, 4.8055e-06],\n",
      "          [5.0480e-06, 4.3387e-06, 4.4213e-06, 3.8644e-06, 4.0022e-06],\n",
      "          [5.8249e-06, 4.2239e-06, 3.5521e-06, 3.1524e-06, 4.0276e-06],\n",
      "          [4.7988e-06, 5.2469e-06, 4.8086e-06, 3.4306e-06, 3.6244e-06],\n",
      "          [6.6807e-06, 5.4838e-06, 5.1112e-06, 3.0719e-06, 2.9431e-06]]],\n",
      "\n",
      "\n",
      "        [[[6.3653e-06, 5.1210e-06, 4.1929e-06, 3.2078e-06, 5.1531e-06],\n",
      "          [7.4303e-06, 6.1263e-06, 4.6653e-06, 4.6436e-06, 6.9549e-06],\n",
      "          [6.9715e-06, 6.2069e-06, 6.0853e-06, 6.6273e-06, 6.5599e-06],\n",
      "          [7.8892e-06, 5.1893e-06, 8.5116e-06, 7.8198e-06, 6.2265e-06],\n",
      "          [5.7991e-06, 6.5065e-06, 8.7483e-06, 6.9621e-06, 6.2315e-06]]],\n",
      "\n",
      "\n",
      "        [[[2.4133e-06, 2.5986e-06, 4.6193e-06, 4.1137e-06, 3.8948e-06],\n",
      "          [4.8206e-06, 4.9047e-06, 5.2740e-06, 4.2030e-06, 3.2175e-06],\n",
      "          [3.5911e-06, 2.5861e-06, 3.4184e-06, 3.9428e-06, 2.8501e-06],\n",
      "          [2.7027e-06, 2.4747e-06, 2.3005e-06, 2.8286e-06, 2.7188e-06],\n",
      "          [2.1811e-06, 2.4897e-06, 2.5322e-06, 2.0315e-06, 2.4816e-06]]],\n",
      "\n",
      "\n",
      "        [[[6.1448e-06, 4.8362e-06, 4.6516e-06, 4.1700e-06, 4.9430e-06],\n",
      "          [5.6918e-06, 3.5364e-06, 3.2462e-06, 3.1956e-06, 3.2328e-06],\n",
      "          [6.9414e-06, 5.1798e-06, 3.0806e-06, 2.9977e-06, 4.7249e-06],\n",
      "          [6.0607e-06, 5.7868e-06, 5.5709e-06, 5.4369e-06, 5.6433e-06],\n",
      "          [8.3216e-06, 7.1455e-06, 6.5261e-06, 6.1991e-06, 5.8973e-06]]],\n",
      "\n",
      "\n",
      "        [[[8.8148e-06, 9.8040e-06, 1.0076e-05, 8.6829e-06, 6.2914e-06],\n",
      "          [8.6795e-06, 1.1269e-05, 1.0693e-05, 9.4774e-06, 4.0186e-06],\n",
      "          [7.5049e-06, 7.8649e-06, 7.8237e-06, 5.1871e-06, 5.0776e-06],\n",
      "          [6.3279e-06, 5.9257e-06, 5.8753e-06, 4.0839e-06, 6.0098e-06],\n",
      "          [6.4407e-06, 6.6816e-06, 5.6311e-06, 5.3293e-06, 5.6166e-06]]],\n",
      "\n",
      "\n",
      "        [[[3.3948e-06, 3.4316e-06, 3.6176e-06, 2.4320e-06, 3.8521e-06],\n",
      "          [3.4258e-06, 3.5087e-06, 4.5776e-06, 5.4305e-06, 7.5133e-06],\n",
      "          [4.5797e-06, 5.8363e-06, 7.3708e-06, 6.7337e-06, 5.8339e-06],\n",
      "          [4.7333e-06, 5.7558e-06, 6.2193e-06, 7.7013e-06, 9.0772e-06],\n",
      "          [3.5739e-06, 5.3318e-06, 5.9233e-06, 6.8303e-06, 7.4169e-06]]],\n",
      "\n",
      "\n",
      "        [[[5.7485e-06, 5.9529e-06, 6.3028e-06, 6.9181e-06, 6.8838e-06],\n",
      "          [3.8636e-06, 4.5650e-06, 6.5401e-06, 6.9064e-06, 5.6451e-06],\n",
      "          [6.1119e-06, 7.0819e-06, 1.0128e-05, 9.0347e-06, 7.8069e-06],\n",
      "          [6.9174e-06, 9.8403e-06, 1.0153e-05, 9.9704e-06, 5.9450e-06],\n",
      "          [7.5780e-06, 8.4842e-06, 8.4213e-06, 7.7128e-06, 8.0827e-06]]],\n",
      "\n",
      "\n",
      "        [[[4.4823e-06, 5.5369e-06, 5.3225e-06, 4.8573e-06, 4.0367e-06],\n",
      "          [4.5823e-06, 2.8935e-06, 3.7367e-06, 4.2051e-06, 4.0382e-06],\n",
      "          [5.8167e-06, 5.4686e-06, 7.5574e-06, 7.6663e-06, 7.9887e-06],\n",
      "          [5.6120e-06, 5.7076e-06, 8.2767e-06, 8.5353e-06, 8.4394e-06],\n",
      "          [5.0981e-06, 4.4932e-06, 4.7312e-06, 5.6075e-06, 6.1275e-06]]],\n",
      "\n",
      "\n",
      "        [[[1.0483e-05, 8.2066e-06, 5.7653e-06, 3.7773e-06, 4.3394e-06],\n",
      "          [6.7778e-06, 3.7796e-06, 4.0893e-06, 4.6966e-06, 4.1351e-06],\n",
      "          [8.0931e-06, 5.8260e-06, 4.9357e-06, 4.1640e-06, 3.5577e-06],\n",
      "          [6.4417e-06, 6.7433e-06, 5.2586e-06, 4.3453e-06, 5.6025e-06],\n",
      "          [4.9494e-06, 4.7639e-06, 4.7911e-06, 5.8897e-06, 5.9293e-06]]],\n",
      "\n",
      "\n",
      "        [[[4.1065e-06, 4.3844e-06, 3.0677e-06, 2.8201e-06, 6.3655e-06],\n",
      "          [4.9197e-06, 5.6089e-06, 3.5978e-06, 2.7342e-06, 9.2591e-06],\n",
      "          [6.0937e-06, 6.5139e-06, 3.4711e-06, 4.8703e-06, 8.5869e-06],\n",
      "          [5.7507e-06, 5.6515e-06, 2.1991e-06, 7.5739e-06, 8.3942e-06],\n",
      "          [7.1898e-06, 5.2083e-06, 6.4000e-06, 7.2308e-06, 7.2900e-06]]],\n",
      "\n",
      "\n",
      "        [[[4.2689e-06, 6.0339e-06, 7.6794e-06, 6.3429e-06, 3.6906e-06],\n",
      "          [5.4085e-06, 8.0884e-06, 8.1576e-06, 5.9387e-06, 5.6255e-06],\n",
      "          [7.9101e-06, 6.8308e-06, 5.4395e-06, 4.3801e-06, 5.1179e-06],\n",
      "          [1.0667e-05, 5.6880e-06, 3.3345e-06, 4.7625e-06, 4.7303e-06],\n",
      "          [8.9618e-06, 4.1867e-06, 5.0392e-06, 5.6101e-06, 3.6034e-06]]],\n",
      "\n",
      "\n",
      "        [[[6.2051e-06, 4.8684e-06, 4.1243e-06, 2.6327e-06, 2.6765e-06],\n",
      "          [5.7520e-06, 3.5662e-06, 2.7047e-06, 2.5911e-06, 2.4153e-06],\n",
      "          [4.0732e-06, 2.6246e-06, 1.9479e-06, 2.4246e-06, 1.8213e-06],\n",
      "          [4.4563e-06, 2.2064e-06, 2.3099e-06, 2.5696e-06, 1.9782e-06],\n",
      "          [3.8764e-06, 2.3557e-06, 2.4988e-06, 2.5224e-06, 2.0601e-06]]],\n",
      "\n",
      "\n",
      "        [[[3.5067e-06, 3.3371e-06, 3.8963e-06, 4.4079e-06, 6.4066e-06],\n",
      "          [4.4024e-06, 3.4220e-06, 2.6312e-06, 6.4484e-06, 8.9472e-06],\n",
      "          [4.3417e-06, 3.8726e-06, 6.3262e-06, 9.0220e-06, 5.1114e-06],\n",
      "          [5.5773e-06, 4.3527e-06, 6.0117e-06, 6.2209e-06, 4.5096e-06],\n",
      "          [6.4316e-06, 3.6597e-06, 6.7761e-06, 7.4947e-06, 6.2858e-06]]],\n",
      "\n",
      "\n",
      "        [[[4.4208e-06, 4.5800e-06, 4.3163e-06, 7.0100e-06, 7.0043e-06],\n",
      "          [6.8209e-06, 5.5924e-06, 4.3885e-06, 5.9800e-06, 5.7482e-06],\n",
      "          [7.3654e-06, 5.0086e-06, 5.2891e-06, 4.9723e-06, 5.1558e-06],\n",
      "          [7.8003e-06, 4.8675e-06, 3.8863e-06, 4.9079e-06, 5.3112e-06],\n",
      "          [5.5172e-06, 3.5719e-06, 4.2631e-06, 5.8428e-06, 5.5926e-06]]],\n",
      "\n",
      "\n",
      "        [[[4.8451e-06, 4.7935e-06, 3.7213e-06, 3.8372e-06, 4.9621e-06],\n",
      "          [5.6794e-06, 5.4455e-06, 4.8030e-06, 4.3012e-06, 5.8706e-06],\n",
      "          [5.8907e-06, 5.9566e-06, 6.4696e-06, 5.5899e-06, 6.2774e-06],\n",
      "          [4.8070e-06, 5.7645e-06, 6.8702e-06, 8.2112e-06, 9.3011e-06],\n",
      "          [6.2563e-06, 7.4229e-06, 7.7136e-06, 7.4394e-06, 7.1838e-06]]],\n",
      "\n",
      "\n",
      "        [[[3.2555e-06, 2.6307e-06, 2.7678e-06, 2.5427e-06, 2.7758e-06],\n",
      "          [2.2869e-06, 3.5224e-06, 4.8558e-06, 3.9691e-06, 2.9137e-06],\n",
      "          [2.3844e-06, 4.3533e-06, 5.1135e-06, 2.5292e-06, 1.3508e-06],\n",
      "          [3.1105e-06, 3.7130e-06, 2.8892e-06, 1.7755e-06, 2.2137e-06],\n",
      "          [4.3981e-06, 3.1050e-06, 2.7186e-06, 2.9255e-06, 3.8021e-06]]],\n",
      "\n",
      "\n",
      "        [[[6.0710e-06, 2.5900e-06, 1.8957e-06, 2.3494e-06, 2.6485e-06],\n",
      "          [5.5743e-06, 2.2981e-06, 1.8238e-06, 2.4890e-06, 2.9329e-06],\n",
      "          [2.2678e-06, 1.7264e-06, 1.7473e-06, 2.2920e-06, 2.4347e-06],\n",
      "          [2.7059e-06, 1.8793e-06, 2.2753e-06, 2.2104e-06, 3.8530e-06],\n",
      "          [1.6563e-06, 2.4161e-06, 3.8350e-06, 5.6432e-06, 6.5653e-06]]],\n",
      "\n",
      "\n",
      "        [[[6.2743e-06, 4.9079e-06, 4.6523e-06, 5.4546e-06, 6.3603e-06],\n",
      "          [6.3396e-06, 5.2602e-06, 6.1442e-06, 6.2008e-06, 6.1459e-06],\n",
      "          [6.4126e-06, 5.4034e-06, 6.6221e-06, 5.0681e-06, 4.1593e-06],\n",
      "          [3.7848e-06, 4.2201e-06, 4.7878e-06, 5.2556e-06, 3.4938e-06],\n",
      "          [3.8901e-06, 4.4965e-06, 4.1339e-06, 3.9254e-06, 3.5073e-06]]],\n",
      "\n",
      "\n",
      "        [[[5.4113e-06, 7.6127e-06, 9.5194e-06, 8.1025e-06, 7.3464e-06],\n",
      "          [4.7065e-06, 6.2530e-06, 6.3323e-06, 7.5957e-06, 6.0925e-06],\n",
      "          [6.0394e-06, 8.1853e-06, 7.0305e-06, 7.2949e-06, 5.7316e-06],\n",
      "          [4.6375e-06, 5.7511e-06, 7.5408e-06, 7.9439e-06, 6.3544e-06],\n",
      "          [3.5212e-06, 6.8585e-06, 7.7793e-06, 7.7382e-06, 6.6968e-06]]],\n",
      "\n",
      "\n",
      "        [[[4.1327e-06, 4.8315e-06, 7.0485e-06, 6.4982e-06, 5.4968e-06],\n",
      "          [6.2638e-06, 6.2417e-06, 5.5034e-06, 5.1918e-06, 6.1397e-06],\n",
      "          [6.8066e-06, 5.9424e-06, 4.8894e-06, 4.4871e-06, 7.2708e-06],\n",
      "          [5.2267e-06, 5.7022e-06, 5.8244e-06, 6.9576e-06, 9.0161e-06],\n",
      "          [5.6410e-06, 4.3024e-06, 7.6369e-06, 8.7423e-06, 1.0294e-05]]],\n",
      "\n",
      "\n",
      "        [[[2.3235e-06, 3.9744e-06, 6.1634e-06, 7.0568e-06, 7.2612e-06],\n",
      "          [2.4989e-06, 4.7101e-06, 3.8301e-06, 3.8223e-06, 4.4262e-06],\n",
      "          [2.8399e-06, 1.7557e-06, 2.5166e-06, 5.7967e-06, 6.6263e-06],\n",
      "          [3.7915e-06, 4.6421e-06, 7.6005e-06, 7.1746e-06, 5.8801e-06],\n",
      "          [5.7583e-06, 7.1650e-06, 7.9423e-06, 5.9104e-06, 4.0121e-06]]]])}, 140466598929608: {'step': 4690, 'square_avg': tensor([5.4031e-05, 2.3488e-05, 1.3780e-05, 4.8701e-05, 3.7247e-05, 9.0052e-06,\n",
      "        7.6676e-05, 7.8601e-06, 1.7034e-05, 3.7183e-05, 1.5783e-05, 6.4218e-06,\n",
      "        1.1596e-04, 1.9086e-05, 1.6382e-05, 1.0696e-05, 4.8267e-05, 7.5113e-05,\n",
      "        2.2942e-05, 1.7549e-05, 9.3012e-05, 2.2366e-05, 2.1965e-05, 1.7397e-05,\n",
      "        2.4005e-05, 2.2236e-05, 1.4400e-05, 2.2132e-05, 3.9827e-05, 3.0064e-05,\n",
      "        3.1603e-05, 2.5171e-05]), 'acc_delta': tensor([8.3123e-06, 4.9158e-06, 5.1592e-06, 6.6912e-06, 1.0414e-05, 4.0731e-06,\n",
      "        6.5934e-06, 3.4530e-06, 5.7598e-06, 7.3766e-06, 4.8954e-06, 2.2577e-06,\n",
      "        9.3364e-06, 7.0254e-06, 4.4669e-06, 3.4747e-06, 6.0784e-06, 8.8280e-06,\n",
      "        6.0439e-06, 5.3543e-06, 9.4261e-06, 6.0117e-06, 6.1873e-06, 5.8161e-06,\n",
      "        6.2930e-06, 4.5096e-06, 5.7018e-06, 6.8168e-06, 7.1674e-06, 6.6714e-06,\n",
      "        6.3379e-06, 4.3463e-06])}, 140466598929896: {'step': 4690, 'square_avg': tensor([[[[2.8752e-06, 7.0360e-06, 7.8692e-06],\n",
      "          [6.1925e-06, 7.3801e-06, 6.3608e-06],\n",
      "          [2.0429e-05, 2.0041e-05, 1.3390e-05]],\n",
      "\n",
      "         [[2.4782e-05, 2.0739e-05, 3.6940e-05],\n",
      "          [2.9174e-05, 1.9648e-05, 5.6122e-05],\n",
      "          [2.6294e-05, 2.8110e-05, 6.6552e-05]],\n",
      "\n",
      "         [[1.9181e-05, 2.0719e-05, 1.4424e-05],\n",
      "          [1.2478e-05, 2.8704e-05, 1.9846e-05],\n",
      "          [2.0521e-05, 3.8883e-05, 2.0247e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.7945e-05, 1.6805e-05, 2.5097e-05],\n",
      "          [2.2289e-05, 2.1288e-05, 2.5462e-05],\n",
      "          [2.5324e-05, 2.3048e-05, 3.2473e-05]],\n",
      "\n",
      "         [[9.2611e-06, 2.4139e-05, 2.4558e-05],\n",
      "          [1.6290e-05, 1.6838e-05, 1.2433e-05],\n",
      "          [2.7998e-05, 1.9403e-05, 1.8308e-05]],\n",
      "\n",
      "         [[1.6566e-05, 1.6359e-05, 1.0428e-05],\n",
      "          [1.9671e-05, 2.6433e-05, 1.3842e-05],\n",
      "          [2.9198e-05, 1.9593e-05, 9.6388e-06]]],\n",
      "\n",
      "\n",
      "        [[[1.1645e-05, 1.1114e-05, 7.9372e-06],\n",
      "          [1.7642e-05, 8.4255e-06, 4.4690e-06],\n",
      "          [1.7285e-05, 1.3807e-05, 7.9387e-06]],\n",
      "\n",
      "         [[7.7467e-05, 7.5660e-05, 3.2265e-05],\n",
      "          [7.1272e-05, 5.2290e-05, 1.3063e-05],\n",
      "          [5.6640e-05, 3.3537e-05, 2.1736e-05]],\n",
      "\n",
      "         [[4.6277e-05, 2.2956e-05, 7.0351e-06],\n",
      "          [3.0275e-05, 8.1115e-06, 9.4808e-06],\n",
      "          [1.4741e-05, 1.2449e-05, 1.8697e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.9035e-05, 4.1423e-05, 2.5447e-05],\n",
      "          [5.1386e-05, 3.9487e-05, 1.5126e-05],\n",
      "          [4.0731e-05, 3.8314e-05, 2.3059e-05]],\n",
      "\n",
      "         [[2.3104e-05, 2.0657e-05, 2.4011e-05],\n",
      "          [4.2732e-05, 2.8672e-05, 1.3630e-05],\n",
      "          [4.0165e-05, 3.5212e-05, 1.1705e-05]],\n",
      "\n",
      "         [[8.0576e-06, 4.8961e-06, 7.5989e-06],\n",
      "          [1.1052e-05, 1.3611e-05, 1.7565e-05],\n",
      "          [1.7939e-05, 1.6679e-05, 2.2626e-05]]],\n",
      "\n",
      "\n",
      "        [[[9.6824e-06, 1.7467e-05, 2.2506e-05],\n",
      "          [7.2664e-06, 1.3947e-05, 1.8370e-05],\n",
      "          [7.9983e-06, 1.3285e-05, 2.4309e-05]],\n",
      "\n",
      "         [[1.4151e-05, 1.8275e-05, 5.7445e-05],\n",
      "          [1.4886e-05, 1.8952e-05, 9.2517e-05],\n",
      "          [1.7380e-05, 3.4734e-05, 1.1663e-04]],\n",
      "\n",
      "         [[2.6090e-05, 3.9945e-05, 5.7246e-05],\n",
      "          [2.7074e-05, 5.8514e-05, 8.2144e-05],\n",
      "          [3.6216e-05, 8.7614e-05, 8.9254e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.1375e-05, 1.8411e-05, 4.9526e-05],\n",
      "          [1.8758e-05, 2.6469e-05, 6.3869e-05],\n",
      "          [1.8636e-05, 2.5461e-05, 6.5923e-05]],\n",
      "\n",
      "         [[2.1890e-05, 3.7416e-05, 4.1250e-05],\n",
      "          [3.6489e-05, 6.2584e-05, 5.0827e-05],\n",
      "          [2.5588e-05, 2.7366e-05, 4.5261e-05]],\n",
      "\n",
      "         [[2.4769e-05, 3.5899e-05, 4.0702e-05],\n",
      "          [2.5973e-05, 4.5027e-05, 4.0080e-05],\n",
      "          [5.8002e-05, 6.5423e-05, 2.5849e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[2.1869e-05, 2.4442e-05, 2.5093e-05],\n",
      "          [1.8346e-05, 2.3038e-05, 2.6273e-05],\n",
      "          [1.4083e-05, 1.9467e-05, 2.6544e-05]],\n",
      "\n",
      "         [[2.7997e-05, 5.6076e-05, 1.0677e-04],\n",
      "          [4.3470e-05, 5.1764e-05, 9.5182e-05],\n",
      "          [4.4466e-05, 4.8247e-05, 9.4084e-05]],\n",
      "\n",
      "         [[6.3471e-05, 6.4623e-05, 3.5169e-05],\n",
      "          [3.6784e-05, 5.1371e-05, 4.6421e-05],\n",
      "          [5.1597e-05, 6.4868e-05, 3.5787e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.0694e-05, 5.2196e-05, 9.2915e-05],\n",
      "          [3.1427e-05, 4.6730e-05, 6.0533e-05],\n",
      "          [3.5747e-05, 3.4363e-05, 7.5004e-05]],\n",
      "\n",
      "         [[3.5800e-05, 5.2830e-05, 4.7831e-05],\n",
      "          [5.0862e-05, 4.5313e-05, 3.6948e-05],\n",
      "          [4.1635e-05, 4.3150e-05, 5.6808e-05]],\n",
      "\n",
      "         [[2.8895e-05, 2.3272e-05, 1.7291e-05],\n",
      "          [4.2254e-05, 3.6090e-05, 1.8983e-05],\n",
      "          [2.4986e-05, 1.2579e-05, 5.4220e-06]]],\n",
      "\n",
      "\n",
      "        [[[1.7006e-05, 1.0187e-05, 6.0227e-06],\n",
      "          [1.4321e-05, 2.1878e-05, 1.9887e-05],\n",
      "          [6.8352e-06, 1.6238e-05, 2.1849e-05]],\n",
      "\n",
      "         [[2.8823e-05, 3.8229e-05, 4.2893e-05],\n",
      "          [1.9001e-05, 5.9722e-05, 5.7335e-05],\n",
      "          [2.1413e-05, 6.6023e-05, 4.7038e-05]],\n",
      "\n",
      "         [[1.9284e-05, 2.3317e-05, 1.8936e-05],\n",
      "          [1.8181e-05, 3.3848e-05, 2.5935e-05],\n",
      "          [4.9081e-05, 2.2824e-05, 1.9251e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.9131e-05, 4.5780e-05, 3.5103e-05],\n",
      "          [3.1775e-05, 3.9513e-05, 4.1569e-05],\n",
      "          [1.2932e-05, 3.2674e-05, 3.6760e-05]],\n",
      "\n",
      "         [[4.8058e-05, 2.1297e-05, 1.6045e-05],\n",
      "          [3.5851e-05, 2.6062e-05, 1.8077e-05],\n",
      "          [1.0306e-05, 3.4795e-05, 4.7274e-05]],\n",
      "\n",
      "         [[5.9401e-06, 1.2938e-05, 1.3530e-05],\n",
      "          [1.6051e-05, 1.3234e-05, 9.5461e-06],\n",
      "          [1.0954e-05, 7.4064e-06, 6.8539e-06]]],\n",
      "\n",
      "\n",
      "        [[[5.7993e-10, 1.3641e-10, 8.2857e-09],\n",
      "          [5.9180e-10, 4.9480e-14, 2.3026e-14],\n",
      "          [3.3905e-09, 3.1099e-11, 2.3973e-12]],\n",
      "\n",
      "         [[4.1426e-09, 2.0510e-10, 1.0478e-08],\n",
      "          [6.2480e-09, 7.9572e-11, 1.2890e-11],\n",
      "          [9.4340e-09, 1.9642e-11, 1.1586e-12]],\n",
      "\n",
      "         [[5.7794e-09, 4.9800e-08, 3.4454e-08],\n",
      "          [3.1916e-11, 1.1069e-11, 3.5072e-10],\n",
      "          [3.8516e-11, 3.7382e-13, 4.2763e-12]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.4389e-09, 3.1428e-24, 4.1570e-09],\n",
      "          [9.2174e-09, 1.4529e-19, 1.5647e-16],\n",
      "          [1.0874e-08, 2.7407e-11, 9.2048e-14]],\n",
      "\n",
      "         [[1.6950e-10, 6.1364e-12, 8.7718e-08],\n",
      "          [1.1658e-13, 1.5619e-14, 6.3319e-11],\n",
      "          [2.8387e-09, 9.5020e-12, 1.5264e-09]],\n",
      "\n",
      "         [[6.4692e-09, 4.6707e-10, 5.5616e-10],\n",
      "          [5.6640e-09, 6.0194e-09, 6.2170e-09],\n",
      "          [6.7576e-09, 6.2264e-09, 7.6856e-09]]]]), 'acc_delta': tensor([[[[1.8902e-06, 3.1215e-06, 3.8400e-06],\n",
      "          [2.2069e-06, 2.7325e-06, 2.7231e-06],\n",
      "          [5.0766e-06, 5.3742e-06, 4.0344e-06]],\n",
      "\n",
      "         [[3.9483e-06, 3.8555e-06, 5.8704e-06],\n",
      "          [4.0286e-06, 4.4765e-06, 7.6928e-06],\n",
      "          [4.1899e-06, 4.9962e-06, 7.9623e-06]],\n",
      "\n",
      "         [[4.2868e-06, 5.1058e-06, 4.3920e-06],\n",
      "          [4.3522e-06, 7.2761e-06, 3.8402e-06],\n",
      "          [4.9907e-06, 6.5802e-06, 3.9132e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.4034e-06, 4.0860e-06, 6.2735e-06],\n",
      "          [4.5452e-06, 4.3580e-06, 4.6050e-06],\n",
      "          [4.3080e-06, 5.4232e-06, 6.7837e-06]],\n",
      "\n",
      "         [[3.3509e-06, 5.9803e-06, 5.4976e-06],\n",
      "          [3.5782e-06, 4.7510e-06, 4.1237e-06],\n",
      "          [4.7328e-06, 3.9674e-06, 4.3674e-06]],\n",
      "\n",
      "         [[6.9176e-06, 6.5194e-06, 3.3331e-06],\n",
      "          [5.8818e-06, 5.8973e-06, 2.7091e-06],\n",
      "          [6.0361e-06, 5.2407e-06, 4.3566e-06]]],\n",
      "\n",
      "\n",
      "        [[[3.9925e-06, 4.0144e-06, 3.6936e-06],\n",
      "          [5.3527e-06, 3.1905e-06, 2.3849e-06],\n",
      "          [6.6160e-06, 5.6953e-06, 3.6120e-06]],\n",
      "\n",
      "         [[7.5993e-06, 7.9952e-06, 5.9610e-06],\n",
      "          [7.9600e-06, 5.9074e-06, 3.5016e-06],\n",
      "          [6.6206e-06, 5.7097e-06, 4.9382e-06]],\n",
      "\n",
      "         [[7.9747e-06, 6.7259e-06, 2.7905e-06],\n",
      "          [5.5020e-06, 3.5091e-06, 4.1708e-06],\n",
      "          [3.8237e-06, 4.0313e-06, 5.4839e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.8917e-06, 5.9859e-06, 5.4823e-06],\n",
      "          [8.2727e-06, 6.9994e-06, 4.7704e-06],\n",
      "          [7.2954e-06, 6.0330e-06, 5.1012e-06]],\n",
      "\n",
      "         [[5.0058e-06, 5.0438e-06, 6.4453e-06],\n",
      "          [8.4345e-06, 6.5235e-06, 4.3543e-06],\n",
      "          [8.8991e-06, 7.7144e-06, 4.1575e-06]],\n",
      "\n",
      "         [[3.4272e-06, 2.9553e-06, 3.5885e-06],\n",
      "          [4.1647e-06, 5.8252e-06, 6.9005e-06],\n",
      "          [6.6990e-06, 6.7843e-06, 8.0584e-06]]],\n",
      "\n",
      "\n",
      "        [[[4.4542e-06, 6.2085e-06, 7.4439e-06],\n",
      "          [4.3105e-06, 6.6394e-06, 6.2572e-06],\n",
      "          [3.6966e-06, 6.1018e-06, 7.8964e-06]],\n",
      "\n",
      "         [[5.1362e-06, 7.2445e-06, 9.1079e-06],\n",
      "          [6.4429e-06, 6.4066e-06, 9.8955e-06],\n",
      "          [5.3091e-06, 8.0957e-06, 9.5919e-06]],\n",
      "\n",
      "         [[8.9883e-06, 9.1443e-06, 8.3662e-06],\n",
      "          [8.9781e-06, 8.6954e-06, 1.0324e-05],\n",
      "          [7.6991e-06, 9.6795e-06, 1.0734e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.5339e-06, 6.4108e-06, 8.5497e-06],\n",
      "          [6.4243e-06, 8.3279e-06, 9.2351e-06],\n",
      "          [5.7351e-06, 7.6343e-06, 8.6443e-06]],\n",
      "\n",
      "         [[5.5527e-06, 7.9280e-06, 8.4947e-06],\n",
      "          [9.1501e-06, 1.2451e-05, 9.2819e-06],\n",
      "          [8.4421e-06, 7.0459e-06, 9.0998e-06]],\n",
      "\n",
      "         [[7.1847e-06, 8.3769e-06, 9.3404e-06],\n",
      "          [7.0376e-06, 8.6885e-06, 8.2547e-06],\n",
      "          [9.8311e-06, 9.7885e-06, 8.1363e-06]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[5.5566e-06, 4.9674e-06, 6.7789e-06],\n",
      "          [4.5533e-06, 5.5640e-06, 6.4072e-06],\n",
      "          [4.8080e-06, 5.3540e-06, 5.4827e-06]],\n",
      "\n",
      "         [[5.7562e-06, 7.5262e-06, 1.0074e-05],\n",
      "          [6.7475e-06, 6.3854e-06, 9.8146e-06],\n",
      "          [6.7992e-06, 5.8406e-06, 7.8089e-06]],\n",
      "\n",
      "         [[7.8999e-06, 9.3457e-06, 7.3017e-06],\n",
      "          [6.7211e-06, 9.1378e-06, 7.7246e-06],\n",
      "          [7.9339e-06, 7.4135e-06, 5.4044e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.6259e-06, 7.6825e-06, 1.0360e-05],\n",
      "          [6.2990e-06, 6.5415e-06, 7.7534e-06],\n",
      "          [6.3828e-06, 5.6363e-06, 7.7444e-06]],\n",
      "\n",
      "         [[6.3061e-06, 7.6071e-06, 7.7560e-06],\n",
      "          [8.0605e-06, 5.8493e-06, 7.1228e-06],\n",
      "          [7.7398e-06, 7.0552e-06, 7.1983e-06]],\n",
      "\n",
      "         [[7.8328e-06, 5.4123e-06, 4.6252e-06],\n",
      "          [8.1054e-06, 5.0367e-06, 4.4724e-06],\n",
      "          [5.3199e-06, 4.6346e-06, 2.6903e-06]]],\n",
      "\n",
      "\n",
      "        [[[6.6395e-06, 4.2452e-06, 3.3520e-06],\n",
      "          [6.2323e-06, 6.6418e-06, 5.3782e-06],\n",
      "          [2.9662e-06, 5.6696e-06, 5.8673e-06]],\n",
      "\n",
      "         [[7.9837e-06, 8.7044e-06, 8.0640e-06],\n",
      "          [4.6144e-06, 1.0526e-05, 9.8523e-06],\n",
      "          [4.1059e-06, 8.6546e-06, 7.7201e-06]],\n",
      "\n",
      "         [[5.6831e-06, 6.1524e-06, 6.1478e-06],\n",
      "          [5.3001e-06, 8.0082e-06, 7.5665e-06],\n",
      "          [9.0527e-06, 5.8645e-06, 5.3695e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[9.0141e-06, 8.1868e-06, 5.9500e-06],\n",
      "          [9.4122e-06, 8.3481e-06, 8.9218e-06],\n",
      "          [3.7801e-06, 6.4266e-06, 7.5640e-06]],\n",
      "\n",
      "         [[9.6171e-06, 5.5003e-06, 5.0543e-06],\n",
      "          [9.9802e-06, 7.3973e-06, 6.0907e-06],\n",
      "          [3.8869e-06, 8.2508e-06, 9.4073e-06]],\n",
      "\n",
      "         [[2.8119e-06, 5.1199e-06, 5.1494e-06],\n",
      "          [5.6120e-06, 4.9363e-06, 4.2279e-06],\n",
      "          [4.2220e-06, 3.1610e-06, 3.5876e-06]]],\n",
      "\n",
      "\n",
      "        [[[5.7869e-10, 1.3640e-10, 8.1472e-09],\n",
      "          [5.9131e-10, 4.9480e-14, 2.3026e-14],\n",
      "          [3.3774e-09, 3.1097e-11, 2.3971e-12]],\n",
      "\n",
      "         [[4.1154e-09, 2.0497e-10, 1.0401e-08],\n",
      "          [6.2106e-09, 7.9557e-11, 1.2889e-11],\n",
      "          [9.2844e-09, 1.9630e-11, 1.1576e-12]],\n",
      "\n",
      "         [[5.7272e-09, 4.7285e-08, 3.3439e-08],\n",
      "          [3.1913e-11, 1.1069e-11, 3.5044e-10],\n",
      "          [3.8504e-11, 3.7373e-13, 4.2763e-12]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.3989e-09, 3.1428e-24, 4.1331e-09],\n",
      "          [9.1424e-09, 1.4529e-19, 1.5647e-16],\n",
      "          [1.0693e-08, 2.7395e-11, 9.2047e-14]],\n",
      "\n",
      "         [[1.6932e-10, 6.1328e-12, 7.8634e-08],\n",
      "          [1.1658e-13, 1.5619e-14, 6.3312e-11],\n",
      "          [2.8239e-09, 9.5014e-12, 1.5203e-09]],\n",
      "\n",
      "         [[6.4248e-09, 4.6662e-10, 5.5565e-10],\n",
      "          [5.6368e-09, 5.9840e-09, 6.1769e-09],\n",
      "          [6.7053e-09, 6.1863e-09, 7.6443e-09]]]])}, 140466598929392: {'step': 4690, 'square_avg': tensor([1.9450e-05, 2.8148e-05, 5.0809e-05, 3.2276e-05, 1.1387e-05, 1.5728e-05,\n",
      "        2.0345e-05, 5.6871e-06, 2.1733e-05, 1.4045e-05, 1.1640e-05, 2.1412e-05,\n",
      "        1.5007e-05, 1.6217e-05, 1.3161e-05, 1.7888e-05, 1.2380e-05, 1.2548e-05,\n",
      "        1.9867e-05, 1.0620e-05, 7.9508e-06, 3.4475e-05, 2.2831e-05, 5.1901e-06,\n",
      "        1.1803e-05, 8.2798e-06, 4.5461e-05, 9.2419e-06, 2.8961e-05, 3.2660e-05,\n",
      "        1.3463e-05, 3.4220e-05, 5.8610e-06, 1.1222e-05, 1.1152e-05, 1.0228e-05,\n",
      "        9.6286e-06, 2.1673e-05, 2.4878e-05, 2.8780e-05, 2.3614e-05, 1.1033e-05,\n",
      "        1.1237e-05, 4.6029e-05, 1.4309e-05, 1.3334e-05, 1.6566e-05, 1.4083e-05,\n",
      "        1.2124e-05, 4.2158e-05, 1.5141e-05, 2.5718e-05, 2.0681e-05, 4.4579e-05,\n",
      "        1.8748e-05, 5.3511e-06, 1.8689e-05, 1.1716e-05, 1.0562e-05, 1.3874e-05,\n",
      "        2.4460e-05, 3.5145e-05, 1.1744e-05, 3.0419e-08]), 'acc_delta': tensor([5.5209e-06, 8.1793e-06, 9.1047e-06, 5.2457e-06, 3.3881e-06, 5.1139e-06,\n",
      "        5.3692e-06, 2.8799e-06, 4.8540e-06, 5.0007e-06, 5.4931e-06, 6.8040e-06,\n",
      "        4.4264e-06, 5.7339e-06, 3.1140e-06, 5.6130e-06, 4.6794e-06, 3.4234e-06,\n",
      "        6.2214e-06, 4.0214e-06, 3.0784e-06, 1.0501e-05, 5.5776e-06, 2.2402e-06,\n",
      "        4.3839e-06, 3.7275e-06, 8.5848e-06, 3.9589e-06, 6.0816e-06, 6.6109e-06,\n",
      "        5.1046e-06, 6.5769e-06, 2.6714e-06, 5.6492e-06, 4.0504e-06, 3.5568e-06,\n",
      "        4.5290e-06, 4.2319e-06, 8.7324e-06, 7.0569e-06, 6.1582e-06, 3.6776e-06,\n",
      "        4.4775e-06, 7.0853e-06, 4.8027e-06, 3.8550e-06, 4.1228e-06, 4.6449e-06,\n",
      "        3.4079e-06, 6.2212e-06, 5.0342e-06, 7.5526e-06, 5.5495e-06, 9.5696e-06,\n",
      "        5.8511e-06, 2.3243e-06, 3.8996e-06, 2.9878e-06, 3.2675e-06, 5.5611e-06,\n",
      "        7.0616e-06, 8.3192e-06, 5.1850e-06, 2.9495e-08])}, 140466598929032: {'step': 4690, 'square_avg': tensor([[4.6611e-05, 1.9394e-04, 2.6855e-04,  ..., 5.6052e-45, 1.4924e-18,\n",
      "         1.7836e-12],\n",
      "        [7.8899e-11, 2.7564e-11, 1.2104e-11,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.1719e-05, 5.5154e-05, 1.0432e-04,  ..., 5.6052e-45, 1.9700e-11,\n",
      "         6.6176e-15],\n",
      "        ...,\n",
      "        [3.0940e-11, 1.1946e-08, 3.4021e-08,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [5.3580e-05, 3.8386e-04, 3.8981e-04,  ..., 5.6052e-45, 9.2734e-16,\n",
      "         1.6037e-11],\n",
      "        [5.2946e-05, 1.7026e-04, 1.4561e-04,  ..., 5.6052e-45, 1.3038e-11,\n",
      "         7.0432e-12]]), 'acc_delta': tensor([[3.6761e-06, 6.4223e-06, 7.2803e-06,  ..., 5.6052e-45, 1.4913e-18,\n",
      "         1.7821e-12],\n",
      "        [7.4683e-11, 2.7031e-11, 1.1481e-11,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.0951e-06, 4.2332e-06, 5.8281e-06,  ..., 5.6052e-45, 1.9697e-11,\n",
      "         6.6174e-15],\n",
      "        ...,\n",
      "        [3.0834e-11, 6.0433e-09, 9.1075e-09,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [5.7249e-06, 1.0109e-05, 9.7762e-06,  ..., 5.6052e-45, 9.2730e-16,\n",
      "         1.6036e-11],\n",
      "        [3.9782e-06, 7.0562e-06, 5.8497e-06,  ..., 5.6052e-45, 1.3036e-11,\n",
      "         7.0430e-12]])}, 140466598928816: {'step': 4690, 'square_avg': tensor([2.3267e-05, 1.1569e-11, 1.2131e-05, 7.4448e-05, 8.8221e-06, 0.0000e+00,\n",
      "        1.1457e-05, 3.7803e-05, 2.0752e-05, 2.9457e-05, 4.3463e-36, 5.3348e-05,\n",
      "        2.0542e-05, 2.3603e-05, 5.6052e-45, 1.1356e-05, 2.4513e-05, 1.2055e-05,\n",
      "        1.5974e-07, 1.7973e-05, 2.1225e-05, 1.6724e-05, 1.1902e-05, 9.4225e-06,\n",
      "        2.9616e-10, 5.6052e-45, 2.1011e-05, 5.6052e-45, 2.4273e-05, 2.8504e-05,\n",
      "        1.6616e-05, 1.9852e-05, 5.6052e-45, 4.3372e-05, 4.8932e-05, 3.6798e-05,\n",
      "        1.5685e-05, 5.3384e-19, 5.6052e-45, 8.8297e-06, 1.4271e-05, 9.6946e-08,\n",
      "        1.5720e-06, 2.1685e-31, 5.5601e-05, 2.9680e-05, 0.0000e+00, 5.6052e-45,\n",
      "        2.1683e-05, 2.0013e-10, 2.8151e-05, 1.2549e-08, 1.9193e-05, 3.1708e-05,\n",
      "        3.6701e-05, 2.0350e-05, 1.8520e-08, 1.2559e-05, 1.6169e-05, 1.0687e-05,\n",
      "        6.8202e-05, 3.6228e-24, 1.1786e-05, 1.4657e-05, 0.0000e+00, 1.4096e-05,\n",
      "        3.2984e-05, 4.8245e-15, 2.2018e-05, 2.0908e-05, 7.6079e-05, 4.2486e-05,\n",
      "        2.2856e-05, 5.9924e-05, 1.5490e-05, 3.7365e-07, 3.3563e-13, 1.3998e-05,\n",
      "        1.9804e-05, 1.0504e-05, 5.9392e-33, 0.0000e+00, 9.3687e-06, 2.0195e-05,\n",
      "        1.9306e-05, 2.8996e-05, 1.7842e-05, 2.6176e-05, 2.0333e-05, 1.1754e-05,\n",
      "        2.2078e-05, 1.6027e-09, 4.9813e-11, 1.8500e-05, 1.0680e-11, 8.7550e-06,\n",
      "        2.6052e-05, 1.6775e-08, 1.8588e-05, 2.0313e-05, 2.2811e-05, 2.6567e-05,\n",
      "        5.6094e-06, 3.5837e-05, 1.7964e-05, 1.3551e-05, 2.9466e-05, 1.0482e-05,\n",
      "        1.4023e-05, 1.8121e-08, 3.6922e-05, 1.2703e-05, 2.0692e-05, 7.5466e-06,\n",
      "        2.9113e-05, 2.7856e-05, 4.7833e-05, 3.4176e-05, 1.7552e-05, 1.3089e-05,\n",
      "        2.1385e-05, 1.3553e-18, 1.1333e-05, 3.5988e-05, 1.9338e-05, 1.8312e-09,\n",
      "        2.7437e-05, 1.5357e-05]), 'acc_delta': tensor([5.5147e-06, 1.1487e-11, 4.0428e-06, 5.1777e-06, 3.9359e-06, 0.0000e+00,\n",
      "        2.9814e-06, 8.4133e-06, 4.4320e-06, 5.8465e-06, 4.3276e-36, 9.4481e-06,\n",
      "        4.3442e-06, 3.8990e-06, 5.6052e-45, 4.0772e-06, 5.4241e-06, 2.6473e-06,\n",
      "        1.0783e-07, 5.5839e-06, 5.5625e-06, 4.1192e-06, 3.3035e-06, 2.1469e-06,\n",
      "        2.7867e-10, 5.6052e-45, 2.9364e-06, 5.6052e-45, 5.2789e-06, 8.0517e-06,\n",
      "        4.9805e-06, 4.2184e-06, 5.6052e-45, 6.6381e-06, 7.1878e-06, 4.3842e-06,\n",
      "        4.0638e-06, 4.1911e-19, 5.6052e-45, 3.6662e-06, 4.9311e-06, 8.8378e-08,\n",
      "        8.7360e-07, 1.8987e-31, 9.9054e-06, 4.5469e-06, 0.0000e+00, 5.6052e-45,\n",
      "        4.8757e-06, 2.0009e-10, 5.1129e-06, 1.2227e-08, 4.9130e-06, 6.2063e-06,\n",
      "        5.6920e-06, 4.3905e-06, 1.7292e-08, 3.1755e-06, 4.8249e-06, 3.0526e-06,\n",
      "        7.9105e-06, 3.6223e-24, 3.4856e-06, 5.4281e-06, 0.0000e+00, 4.6252e-06,\n",
      "        6.9175e-06, 4.8245e-15, 4.4741e-06, 4.5897e-06, 8.4517e-06, 9.2677e-06,\n",
      "        5.7791e-06, 8.1889e-06, 3.6524e-06, 1.9180e-07, 3.2240e-13, 3.5640e-06,\n",
      "        4.6988e-06, 2.3340e-06, 5.8104e-33, 0.0000e+00, 3.0656e-06, 5.4225e-06,\n",
      "        3.9051e-06, 7.5328e-06, 3.0082e-06, 5.3691e-06, 5.0783e-06, 3.6048e-06,\n",
      "        5.3384e-06, 1.5597e-09, 4.9768e-11, 3.6101e-06, 1.0347e-11, 2.5323e-06,\n",
      "        5.4579e-06, 1.6311e-08, 4.8395e-06, 4.1852e-06, 5.9575e-06, 5.8698e-06,\n",
      "        2.5786e-06, 7.2401e-06, 4.8910e-06, 3.1213e-06, 7.2421e-06, 3.0907e-06,\n",
      "        3.8313e-06, 1.1423e-08, 5.4041e-06, 3.9848e-06, 5.3535e-06, 2.1544e-06,\n",
      "        4.0299e-06, 4.0969e-06, 6.8807e-06, 6.5190e-06, 4.9568e-06, 3.5877e-06,\n",
      "        4.5226e-06, 1.0657e-18, 3.4431e-06, 7.0562e-06, 5.0736e-06, 1.5925e-09,\n",
      "        6.3232e-06, 5.2631e-06])}, 140466598930760: {'step': 4690, 'square_avg': tensor([[1.2367e-04, 5.6052e-45, 5.7110e-05,  ..., 1.3470e-14, 6.6883e-04,\n",
      "         1.5577e-04],\n",
      "        [9.8229e-04, 5.6052e-45, 2.5994e-03,  ..., 3.6434e-43, 2.3987e-04,\n",
      "         8.0104e-05],\n",
      "        [3.8701e-03, 5.6052e-45, 3.9188e-04,  ..., 5.1610e-18, 1.1847e-03,\n",
      "         1.3422e-03],\n",
      "        ...,\n",
      "        [2.4340e-03, 2.9438e-12, 5.0776e-04,  ..., 5.6052e-45, 1.6115e-03,\n",
      "         1.5671e-04],\n",
      "        [3.9395e-03, 5.6052e-45, 4.2334e-04,  ..., 9.1896e-12, 1.8533e-03,\n",
      "         7.2890e-04],\n",
      "        [2.7084e-03, 5.6052e-45, 2.0385e-03,  ..., 1.4072e-11, 5.7147e-03,\n",
      "         1.3912e-04]]), 'acc_delta': tensor([[1.3497e-06, 5.6052e-45, 7.9325e-07,  ..., 1.3105e-14, 1.2525e-06,\n",
      "         1.3123e-06],\n",
      "        [3.2387e-06, 5.6052e-45, 4.4512e-06,  ..., 1.2191e-43, 3.6675e-06,\n",
      "         1.5680e-06],\n",
      "        [5.5506e-06, 5.6052e-45, 2.3941e-06,  ..., 5.0307e-18, 6.0805e-06,\n",
      "         3.8352e-06],\n",
      "        ...,\n",
      "        [6.9860e-06, 2.9004e-12, 2.1395e-06,  ..., 5.6052e-45, 1.9290e-06,\n",
      "         2.3441e-06],\n",
      "        [3.8891e-06, 5.6052e-45, 3.9811e-06,  ..., 8.8869e-12, 2.7390e-06,\n",
      "         2.5324e-06],\n",
      "        [5.3740e-06, 5.6052e-45, 3.2657e-06,  ..., 1.3763e-11, 5.5477e-06,\n",
      "         3.7911e-06]])}, 140466598929248: {'step': 4690, 'square_avg': tensor([0.0003, 0.0004, 0.0010, 0.0006, 0.0007, 0.0013, 0.0007, 0.0008, 0.0008,\n",
      "        0.0006]), 'acc_delta': tensor([4.3735e-06, 7.3998e-06, 9.5773e-06, 6.3916e-06, 6.7001e-06, 6.9973e-06,\n",
      "        7.9686e-06, 9.4280e-06, 5.9365e-06, 5.5545e-06])}}\n",
      "param_groups \t [{'lr': 0.0016806999999999992, 'rho': 0.9, 'eps': 1e-06, 'weight_decay': 0, 'initial_lr': 0.01, 'params': [140466598930328, 140466598929608, 140466598929896, 140466598929392, 140466598929032, 140466598928816, 140466598930760, 140466598929248]}]\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image, example_label = next(iter(train_loader))\n",
    "# run the tracing\n",
    "traced_script_module = torch.jit.trace(model, example_image)\n",
    "# save the converted model\n",
    "traced_script_module.save(\"./models/converted_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
